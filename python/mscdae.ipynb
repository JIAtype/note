{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee150a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import logging\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd03e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a9f39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 10:59:36,315 - INFO - device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 设备选择\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1addd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        \n",
    "        # 检查文件夹是否存在\n",
    "        if not self.image_dir.exists():\n",
    "            raise FileNotFoundError(f\"图像目录 '{image_dir}' 不存在\")\n",
    "        \n",
    "        # 获取支持的图像文件\n",
    "        self.images = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "        \n",
    "        # 检查是否有图像文件\n",
    "        if len(self.images) == 0:\n",
    "            raise ValueError(f\"图像目录 '{image_dir}' 中没有找到支持的图像文件(.png, .jpg, .jpeg, .bmp)\")\n",
    "        \n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        logger.info(f\"已加载 {len(self.images)} 张图像\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')  # 确保图像是RGB格式\n",
    "            image_tensor = self.transform(image)\n",
    "            return image_tensor\n",
    "        except Exception as e:\n",
    "            logger.error(f\"加载图像 '{img_path}' 时出错: {e}\")\n",
    "            # 返回一个空白图像作为替代\n",
    "            return torch.zeros((1, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96fa8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianPyramid(nn.Module):\n",
    "    def __init__(self, levels=3):\n",
    "        super(GaussianPyramid, self).__init__()\n",
    "        self.levels = levels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 生成高斯金字塔\n",
    "        pyramid = [x]\n",
    "        current = x\n",
    "        for _ in range(1, self.levels):\n",
    "            # 使用平均池化模拟高斯下采样\n",
    "            current = F.avg_pool2d(current, kernel_size=2, stride=2)\n",
    "            pyramid.append(current)\n",
    "        return pyramid\n",
    "\n",
    "class MultiScaleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MultiScaleConvBlock, self).__init__()\n",
    "        # 高斯金字塔\n",
    "        self.gaussian_pyramid = GaussianPyramid(levels=3)\n",
    "        \n",
    "        # 多尺度卷积\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=k, padding=k//2),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ) for k in [1, 3, 5]\n",
    "        ])\n",
    "        \n",
    "        # 计算输出通道数 (3个卷积核尺寸 * 3个金字塔级别 * out_channels)\n",
    "        self.output_channels = 3 * 3 * out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 获取高斯金字塔\n",
    "        pyramid_features = self.gaussian_pyramid(x)\n",
    "        \n",
    "        # 存储多尺度特征\n",
    "        multi_scale_features = []\n",
    "        \n",
    "        # 在每个金字塔层级应用卷积\n",
    "        for level in pyramid_features:\n",
    "            level_features = [conv(level) for conv in self.conv_layers]\n",
    "            \n",
    "            #报错\n",
    "            # 确保所有特征图尺寸一致\n",
    "            # if level != pyramid_features[0]:\n",
    "            #     level_features = [F.interpolate(feat, size=pyramid_features[0].shape[2:]) \n",
    "            #                     for feat in level_features]\n",
    "                \n",
    "            # 另一种修改方式:\n",
    "            if level.shape != pyramid_features[0].shape:\n",
    "                level_features = [F.interpolate(feat, size=pyramid_features[0].shape[2:]) \n",
    "                                for feat in level_features]\n",
    "\n",
    "            multi_scale_features.extend(level_features)\n",
    "        \n",
    "        # 特征融合\n",
    "        return torch.cat(multi_scale_features, dim=1)\n",
    "\n",
    "class MSCDAE(nn.Module):\n",
    "    def __init__(self, input_channels=1):\n",
    "        super(MSCDAE, self).__init__()\n",
    "        \n",
    "        # 定义每层的通道数\n",
    "        self.encoder_channels = [input_channels, 16, 32]\n",
    "        \n",
    "        # 编码器\n",
    "        self.encoder_block1 = MultiScaleConvBlock(self.encoder_channels[0], self.encoder_channels[1])\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.encoder_block2 = MultiScaleConvBlock(self.encoder_block1.output_channels, self.encoder_channels[2])\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # 获取编码器最终输出通道数\n",
    "        self.bottleneck_channels = self.encoder_block2.output_channels\n",
    "        \n",
    "        # 解码器\n",
    "        self.upconv1 = nn.ConvTranspose2d(self.bottleneck_channels, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.decoder_block1 = MultiScaleConvBlock(32, 16)\n",
    "        self.upconv2 = nn.ConvTranspose2d(self.decoder_block1.output_channels, 16, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.decoder_block2 = MultiScaleConvBlock(16, 8)\n",
    "        self.final_conv = nn.Conv2d(self.decoder_block2.output_channels, input_channels, kernel_size=1)\n",
    "        \n",
    "        # 添加Sigmoid激活保证输出在[0,1]范围\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 添加噪声 (根据输入强度自适应)\n",
    "        noise_level = 0.1 * torch.mean(x)\n",
    "        noise = torch.randn_like(x) * noise_level\n",
    "        x_noisy = torch.clamp(x + noise, 0, 1)\n",
    "        \n",
    "        # 编码\n",
    "        e1 = self.encoder_block1(x_noisy)\n",
    "        e1_pool = self.pool1(e1)\n",
    "        e2 = self.encoder_block2(e1_pool)\n",
    "        e2_pool = self.pool2(e2)\n",
    "        \n",
    "        # 解码\n",
    "        d1 = self.upconv1(e2_pool)\n",
    "        d1_block = self.decoder_block1(d1)\n",
    "        d2 = self.upconv2(d1_block)\n",
    "        d2_block = self.decoder_block2(d2)\n",
    "        output = self.final_conv(d2_block)\n",
    "        \n",
    "        # 确保输出在[0,1]范围内\n",
    "        return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c74a3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mscdae(model, train_loader, criterion, optimizer, device, epochs=50, save_path='checkpoints'):\n",
    "    # 创建保存检查点的目录\n",
    "    save_dir = Path(save_path)\n",
    "    save_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            # 将数据移至设备\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 前向传播\n",
    "            reconstructed = model(batch)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = criterion(reconstructed, batch)\n",
    "            \n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 打印批次进度\n",
    "            if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                logger.info(f'Epoch [{epoch+1}/{epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        logger.info(f'Epoch [{epoch+1}/{epochs}], Average Loss: {avg_loss:.4f}')\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_loss,\n",
    "            }, save_dir / 'best_model.pth')\n",
    "            logger.info(f'已保存最佳模型, Loss: {best_loss:.4f}')\n",
    "        \n",
    "        # 每10个epoch保存一次检查点\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "            }, save_dir / f'checkpoint_epoch_{epoch+1}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2d8b386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\aiml\\skc_ai\\venv_skc_ai\\lib\\site-packages (2.6.0+cpu)\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp311-cp311-win_amd64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: torchvision in d:\\aiml\\skc_ai\\venv_skc_ai\\lib\\site-packages (0.21.0+cpu)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.0-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: filelock in d:\\aiml\\skc_ai\\venv_skc_ai\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\aiml\\skc_ai\\venv_skc_ai\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in d:\\aiml\\skc_ai\\venv_skc_ai\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\aiml\\skc_ai\\venv_skc_ai\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\aiml\\skc_ai\\venv_skc_ai\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy in d:\\aiml\\skc_ai\\venv_skc_ai\\lib\\site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\aiml\\skc_ai\\venv_skc_ai\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\aiml\\skc_ai\\venv_skc_ai\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\aiml\\skc_ai\\venv_skc_ai\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.7.0-cp311-cp311-win_amd64.whl (212.5 MB)\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/212.5 MB 7.2 MB/s eta 0:00:30\n",
      "   ---------------------------------------- 1.1/212.5 MB 12.1 MB/s eta 0:00:18\n",
      "   ---------------------------------------- 2.4/212.5 MB 15.5 MB/s eta 0:00:14\n",
      "    --------------------------------------- 3.8/212.5 MB 20.3 MB/s eta 0:00:11\n",
      "    --------------------------------------- 5.1/212.5 MB 21.8 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 6.7/212.5 MB 23.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 7.2/212.5 MB 22.0 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 9.0/212.5 MB 23.9 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 10.5/212.5 MB 26.2 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 12.1/212.5 MB 28.5 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 14.2/212.5 MB 31.2 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 16.4/212.5 MB 32.7 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 18.2/212.5 MB 36.4 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 20.1/212.5 MB 38.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 22.1/212.5 MB 38.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 23.5/212.5 MB 40.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 25.1/212.5 MB 38.6 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 27.3/212.5 MB 38.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 28.9/212.5 MB 38.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 31.0/212.5 MB 38.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 32.5/212.5 MB 38.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 34.4/212.5 MB 36.4 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 36.2/212.5 MB 38.5 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 37.6/212.5 MB 34.4 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 39.6/212.5 MB 34.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 41.0/212.5 MB 34.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 42.1/212.5 MB 34.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 43.9/212.5 MB 36.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 45.8/212.5 MB 34.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 46.6/212.5 MB 36.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 48.2/212.5 MB 34.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 50.0/212.5 MB 34.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 51.8/212.5 MB 34.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 53.2/212.5 MB 34.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 55.1/212.5 MB 34.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 57.5/212.5 MB 38.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 58.7/212.5 MB 38.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 60.1/212.5 MB 36.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 61.6/212.5 MB 36.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 63.4/212.5 MB 34.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 64.5/212.5 MB 34.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 66.2/212.5 MB 32.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 67.9/212.5 MB 31.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 68.9/212.5 MB 31.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 70.0/212.5 MB 31.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 71.6/212.5 MB 32.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 73.2/212.5 MB 32.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 74.0/212.5 MB 31.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 74.8/212.5 MB 29.7 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 75.5/212.5 MB 27.3 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 76.1/212.5 MB 26.2 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 76.9/212.5 MB 24.2 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 77.4/212.5 MB 22.6 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 78.2/212.5 MB 21.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 78.8/212.5 MB 19.3 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 79.6/212.5 MB 19.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 80.1/212.5 MB 18.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 80.8/212.5 MB 17.7 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 81.6/212.5 MB 16.4 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 82.4/212.5 MB 16.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 83.1/212.5 MB 15.2 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 84.0/212.5 MB 15.2 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 85.0/212.5 MB 15.2 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 86.1/212.5 MB 15.6 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 87.0/212.5 MB 16.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 87.8/212.5 MB 16.4 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 88.9/212.5 MB 17.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 89.7/212.5 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 90.8/212.5 MB 18.2 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 92.0/212.5 MB 18.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 93.1/212.5 MB 19.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 93.7/212.5 MB 19.8 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 94.2/212.5 MB 18.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 95.2/212.5 MB 18.7 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 96.5/212.5 MB 19.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 97.9/212.5 MB 20.5 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 99.1/212.5 MB 21.1 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 100.0/212.5 MB 21.1 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 101.0/212.5 MB 21.1 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 102.0/212.5 MB 21.1 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 103.2/212.5 MB 21.1 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 104.1/212.5 MB 22.6 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 105.5/212.5 MB 24.2 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 106.6/212.5 MB 25.2 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 107.8/212.5 MB 25.2 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 109.4/212.5 MB 25.2 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 110.7/212.5 MB 25.2 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 112.1/212.5 MB 26.2 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 113.0/212.5 MB 24.2 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 114.7/212.5 MB 26.2 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 115.6/212.5 MB 26.2 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 116.8/212.5 MB 26.2 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 118.7/212.5 MB 27.3 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 120.1/212.5 MB 29.7 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 121.4/212.5 MB 27.3 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 123.2/212.5 MB 31.2 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 124.1/212.5 MB 28.5 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 125.8/212.5 MB 31.2 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 127.3/212.5 MB 32.8 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 129.1/212.5 MB 31.2 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 130.6/212.5 MB 32.7 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 132.0/212.5 MB 34.4 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 133.8/212.5 MB 34.4 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 135.4/212.5 MB 36.3 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 136.7/212.5 MB 34.6 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 138.4/212.5 MB 32.7 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 140.4/212.5 MB 32.7 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 141.5/212.5 MB 32.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 143.1/212.5 MB 34.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 144.0/212.5 MB 31.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 145.5/212.5 MB 29.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 147.0/212.5 MB 31.2 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 148.6/212.5 MB 31.2 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 150.3/212.5 MB 29.7 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 151.9/212.5 MB 29.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 153.7/212.5 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 155.1/212.5 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 156.7/212.5 MB 32.8 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 158.3/212.5 MB 31.1 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 159.9/212.5 MB 32.7 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 161.1/212.5 MB 32.7 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 162.3/212.5 MB 31.1 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 163.5/212.5 MB 29.8 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 165.0/212.5 MB 29.8 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 166.1/212.5 MB 27.3 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 167.8/212.5 MB 29.7 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 169.2/212.5 MB 28.4 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 170.7/212.5 MB 28.5 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 171.9/212.5 MB 28.4 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 173.6/212.5 MB 29.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 175.2/212.5 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 176.8/212.5 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 178.2/212.5 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 179.7/212.5 MB 31.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 181.4/212.5 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 182.7/212.5 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 184.2/212.5 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 185.4/212.5 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 186.5/212.5 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 187.8/212.5 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 189.7/212.5 MB 31.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 190.9/212.5 MB 28.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 192.5/212.5 MB 29.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 193.9/212.5 MB 29.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 195.6/212.5 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 197.1/212.5 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 198.8/212.5 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 200.3/212.5 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 201.9/212.5 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 202.9/212.5 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 204.0/212.5 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 205.6/212.5 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  207.1/212.5 MB 31.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  208.7/212.5 MB 29.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  209.9/212.5 MB 27.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  211.5/212.5 MB 28.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 212.5/212.5 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.22.0-cp311-cp311-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 1.1/1.7 MB 36.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 21.9 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.4/6.3 MB 44.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.5/6.3 MB 26.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.0/6.3 MB 28.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.3 MB 27.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 26.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 25.2 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy, torch, torchvision\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0+cpu\n",
      "    Uninstalling torch-2.6.0+cpu:\n",
      "      Successfully uninstalled torch-2.6.0+cpu\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.21.0+cpu\n",
      "    Uninstalling torchvision-0.21.0+cpu:\n",
      "      Successfully uninstalled torchvision-0.21.0+cpu\n",
      "Successfully installed sympy-1.14.0 torch-2.7.0 torchvision-0.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\aiml\\skc_ai\\venv_skc_ai\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\aiml\\skc_ai\\venv_skc_ai\\Lib\\site-packages\\~orchvision'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.6.0+cpu requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08a28351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数，测试集目录\n",
    "# D:\\aiml\\mscdae_defect_detector\\datasets\\train_ac_samples\n",
    "image_dir = 'D://aiml/mscdae_defect_detector/datasets/train_ac_samples'\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab03f135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 12:05:24,578 - INFO - 已加载 8 张图像\n",
      "2025-05-19 12:05:24,580 - INFO - 训练集: 6 样本, 验证集: 2 样本\n",
      "2025-05-19 12:05:24,591 - INFO - 初始化模型: MSCDAE\n",
      "2025-05-19 12:05:24,593 - INFO - 开始训练...\n",
      "2025-05-19 12:05:24,596 - ERROR - 发生错误: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\splsip258\\AppData\\Local\\Temp\\ipykernel_28464\\3077228549.py\", line 25, in <module>\n",
      "    train_mscdae(model, train_loader, criterion, optimizer, device, epochs=epochs)\n",
      "  File \"C:\\Users\\splsip258\\AppData\\Local\\Temp\\ipykernel_28464\\793424752.py\", line 11, in train_mscdae\n",
      "    for batch_idx, batch in enumerate(train_loader):\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\aiml\\skc_ai\\venv_skc_ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 491, in __iter__\n",
      "    return self._iterator\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\aiml\\skc_ai\\venv_skc_ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 419, in _get_iterator\n",
      "    def _get_iterator(self) -> \"_BaseDataLoaderIter\":\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\aiml\\skc_ai\\venv_skc_ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 743, in __init__\n",
      "    )\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # 数据集和数据加载器\n",
    "    dataset = Dataset(image_dir)\n",
    "    \n",
    "    # 划分训练集和验证集 (80% 训练, 20% 验证)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, timeout=60)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, timeout=60)\n",
    "    \n",
    "    logger.info(f\"训练集: {train_size} 样本, 验证集: {val_size} 样本\")\n",
    "    \n",
    "    # 模型初始化\n",
    "    model = MSCDAE().to(device)\n",
    "    logger.info(f\"初始化模型: {model.__class__.__name__}\")\n",
    "    \n",
    "    # 损失函数和优化器\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # 训练\n",
    "    logger.info(\"开始训练...\")\n",
    "    train_mscdae(model, train_loader, criterion, optimizer, device, epochs=epochs)\n",
    "    \n",
    "    # 保存最终模型\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, 'models/final_mscdae_model.pth')\n",
    "    logger.info(\"训练完成，模型已保存\")\n",
    "    \n",
    "    # 在验证集上评估\n",
    "    # 对于自编码器等模型，重构损失（如均方误差MSE）可以用来评估模型的性能。\n",
    "    # 正常样本的重构损失通常较低，而异常样本的重构损失较高。\n",
    "    # 因此，可以通过监控重构损失来判断模型的训练效果。\n",
    "    logger.info(\"在验证集上评估...\")\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            reconstructed = model(batch)\n",
    "            loss = criterion(reconstructed, batch)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    logger.info(f\"验证集平均损失: {avg_val_loss:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"发生错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a7c856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import argparse\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d899f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path, transform=None):\n",
    "    \"\"\"加载并预处理单张图像\"\"\"\n",
    "    if transform is None:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        tensor = transform(image)\n",
    "        return tensor, image\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load image '{image_path}' : {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfa9f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(results, save_path=None):\n",
    "    \"\"\"可视化检测结果\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # 原始图像\n",
    "    axes[0, 0].imshow(results['original'].permute(1, 2, 0).cpu().numpy())\n",
    "    axes[0, 0].set_title('Original Image')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # 重建图像\n",
    "    axes[0, 1].imshow(results['reconstructed'].permute(1, 2, 0).cpu().numpy())\n",
    "    axes[0, 1].set_title('Reconstructing the image')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # 误差图\n",
    "    error_map = results['error_map'].cpu().numpy()\n",
    "    im = axes[1, 0].imshow(error_map, cmap='jet')\n",
    "    axes[1, 0].set_title(f'Reconstruction error (mean: {error_map.mean():.4f})')\n",
    "    axes[1, 0].axis('off')\n",
    "    fig.colorbar(im, ax=axes[1, 0], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # 缺陷掩码\n",
    "    axes[1, 1].imshow(results['defect_mask'].cpu().numpy(), cmap='gray')\n",
    "    axes[1, 1].set_title(f'Defect Mask (Threshold: {results[\"threshold\"]:.4f})')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        logger.info(f\"Results saved to {save_path}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af279453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_defect_mask(original_image, defect_mask, color=(0, 0, 255), alpha=0.5):\n",
    "    \"\"\"在原始图像上应用缺陷掩码，突出显示缺陷区域\"\"\"\n",
    "    # 将原始图像转换为NumPy数组\n",
    "    if isinstance(original_image, torch.Tensor):\n",
    "        # 如果是张量，转换为NumPy数组并确保通道顺序正确(C,H,W -> H,W,C)\n",
    "        original_np = original_image.permute(1, 2, 0).cpu().numpy()\n",
    "    elif isinstance(original_image, Image.Image):\n",
    "        # 如果是PIL图像，转换为NumPy数组\n",
    "        original_np = np.array(original_image)\n",
    "    else:\n",
    "        original_np = original_image\n",
    "    \n",
    "    # 确保值范围在0-1之间\n",
    "    if original_np.max() <= 1.0:\n",
    "        original_np = (original_np * 255).astype(np.uint8)\n",
    "    \n",
    "    # 创建RGB图像(如果是灰度图)\n",
    "    if len(original_np.shape) == 2 or original_np.shape[2] == 1:\n",
    "        original_np = cv2.cvtColor(original_np, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # 创建与原图相同大小的掩码图像\n",
    "    mask_np = cv2.resize(defect_mask.cpu().numpy().astype(np.uint8) * 255, \n",
    "                         (original_np.shape[1], original_np.shape[0]))\n",
    "    \n",
    "    # 创建一个彩色覆盖图\n",
    "    overlay = original_np.copy()\n",
    "    overlay[mask_np > 0] = color\n",
    "    \n",
    "    # 将覆盖图与原图混合\n",
    "    highlighted = cv2.addWeighted(overlay, alpha, original_np, 1 - alpha, 0)\n",
    "    \n",
    "    return highlighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_defects(model, image, device, threshold_factor=2.0):\n",
    "    \"\"\"检测图像中的缺陷\"\"\"\n",
    "    # 确保模型在评估模式\n",
    "    model.eval()\n",
    "    \n",
    "    # 将图像移至设备\n",
    "    image = image.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 获取重建图像\n",
    "        reconstructed = model(image.unsqueeze(0)).squeeze(0)\n",
    "        \n",
    "        # 计算重建误差\n",
    "        error_map = torch.abs(image - reconstructed)\n",
    "        \n",
    "        # 计算每个通道的误差统计\n",
    "        if error_map.dim() > 2:  # 多通道图像\n",
    "            # 转换为灰度误差图\n",
    "            error_map = torch.mean(error_map, dim=0)\n",
    "        \n",
    "        # 设置自适应阈值\n",
    "        threshold = error_map.mean() + threshold_factor * error_map.std()\n",
    "        defect_mask = error_map > threshold\n",
    "        \n",
    "        # 返回结果\n",
    "        return {\n",
    "            'original': image.cpu(),\n",
    "            'reconstructed': reconstructed.cpu(),\n",
    "            'error_map': error_map.cpu(),\n",
    "            'defect_mask': defect_mask.cpu(),\n",
    "            'threshold': threshold.item()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fed3f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_image(model, image_path, device, threshold_factor=2.0, save_dir=None):\n",
    "    \"\"\"测试单张图像并可视化结果\"\"\"\n",
    "    # 加载并预处理图像\n",
    "    image_tensor, original_image = load_and_preprocess_image(image_path)\n",
    "    if image_tensor is None:\n",
    "        return\n",
    "    \n",
    "    # 检测缺陷\n",
    "    results = detect_defects(model, image_tensor, device, threshold_factor)\n",
    "    \n",
    "    # 可视化结果\n",
    "    if save_dir:\n",
    "        save_path = os.path.join(save_dir, f\"{Path(image_path).stem}_results.png\")\n",
    "    else:\n",
    "        save_path = None\n",
    "    \n",
    "    visualize_results(results, save_path)\n",
    "    \n",
    "    # 在原始图像上标记缺陷\n",
    "    highlighted_image = apply_defect_mask(original_image, results['defect_mask'])\n",
    "    \n",
    "    if save_dir:\n",
    "        highlight_path = os.path.join(save_dir, f\"{Path(image_path).stem}_highlighted.png\")\n",
    "        cv2.imwrite(highlight_path, cv2.cvtColor(highlighted_image, cv2.COLOR_RGB2BGR))\n",
    "        logger.info(f\"标记的图像已保存至 {highlight_path}\")\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(highlighted_image)\n",
    "    plt.title(\"Marked defects\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f407ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_defects(model, image, device, threshold_factor=2.0):\n",
    "    \"\"\"检测图像中的缺陷\"\"\"\n",
    "    # 确保模型在评估模式\n",
    "    model.eval()\n",
    "    \n",
    "    # 将图像移至设备\n",
    "    image = image.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 获取重建图像\n",
    "        reconstructed = model(image.unsqueeze(0)).squeeze(0)\n",
    "        \n",
    "        # 计算重建误差\n",
    "        error_map = torch.abs(image - reconstructed)\n",
    "        \n",
    "        # 计算每个通道的误差统计\n",
    "        if error_map.dim() > 2:  # 多通道图像\n",
    "            # 转换为灰度误差图\n",
    "            error_map = torch.mean(error_map, dim=0)\n",
    "        \n",
    "        # 设置自适应阈值\n",
    "        threshold = error_map.mean() + threshold_factor * error_map.std()\n",
    "        defect_mask = error_map > threshold\n",
    "        \n",
    "        # 返回结果\n",
    "        return {\n",
    "            'original': image.cpu(),\n",
    "            'reconstructed': reconstructed.cpu(),\n",
    "            'error_map': error_map.cpu(),\n",
    "            'defect_mask': defect_mask.cpu(),\n",
    "            'threshold': threshold.item()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch_images(model, image_dir, device, threshold_factor=2.0, save_dir=None):\n",
    "    \"\"\"测试文件夹中的所有图像\"\"\"\n",
    "    # 确保保存目录存在\n",
    "    if save_dir:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 获取所有图像文件\n",
    "    image_files = [f for f in os.listdir(image_dir) \n",
    "                  if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "    \n",
    "    if not image_files:\n",
    "        logger.error(f\"目录 '{image_dir}' 中没有找到图像文件\")\n",
    "        return\n",
    "    \n",
    "    logger.info(f\"找到 {len(image_files)} 个图像文件\")\n",
    "    \n",
    "    # 对每个图像进行测试\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        logger.info(f\"处理图像: {image_path}\")\n",
    "        try:\n",
    "            test_single_image(model, image_path, device, threshold_factor, save_dir)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"处理图像 '{image_path}' 时出错: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56e4468",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'mscdae_defect_detector/models/final_mscdae_model.pth'  # 模型权重文件路径\n",
    "data_dir = 'mscdae_defect_detector/datasets/test_nc_samples'           # 包含测试图像的目录\n",
    "single_image = None                       # 单张图像的路径（可选）\n",
    "threshold = 2.0                          # 缺陷检测阈值因子\n",
    "output_dir = 'outputs/250519-1130'               # 保存结果的目录\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "logger.info(f\"已加载模型 '{model_path}'\")\n",
    "\n",
    "# 创建输出目录\n",
    "if output_dir:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 测试模型\n",
    "if single_image:\n",
    "    if os.path.exists(single_image):\n",
    "        logger.info(f\"测试单张图像: {single_image}\")\n",
    "        test_single_image(model, single_image, device, threshold, output_dir)\n",
    "    else:\n",
    "        logger.error(f\"图像文件 '{single_image}' 不存在\")\n",
    "else:\n",
    "    if os.path.exists(data_dir):\n",
    "        logger.info(f\"测试目录中的所有图像: {data_dir}\")\n",
    "        test_batch_images(model, data_dir, device, threshold, output_dir)\n",
    "    else:\n",
    "        logger.error(f\"数据目录 '{data_dir}' 不存在\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_skc_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
