{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35a0018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f42fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 12:56:58,839 - root - INFO - Logging system initialized\n",
      "2025-05-19 12:56:58,841 - PreprocessingModule - INFO - Preprocessing module initialized\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "try:\n",
    "    # Ensure log directory exists\n",
    "    log_dir = os.path.dirname(os.path.abspath(\"logs/preprocessing.log\"))\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    # Configure logging\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(\"preprocessing.log\", mode='w'),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    # Force output of initial log to confirm logging system is working\n",
    "    logging.info(\"Logging system initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"Error setting up logging system: {str(e)}\")\n",
    "    \n",
    "logger = logging.getLogger(\"PreprocessingModule\")\n",
    "# Confirm logger is working properly\n",
    "logger.info(\"Preprocessing module initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89f80448",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PreprocessingConfig:\n",
    "    \"\"\"Preprocessing module configuration\"\"\"\n",
    "    target_size: Tuple[int, int] = (1024, 1024)  # Target size (height, width)\n",
    "    normalize: bool = True                       # Whether to normalize pixel values\n",
    "    clahe_clip_limit: float = 2.0                # CLAHE contrast limit\n",
    "    clahe_grid_size: Tuple[int, int] = (8, 8)    # CLAHE grid size\n",
    "    denoise_h: int = 10                          # Denoising strength\n",
    "    gamma_correction: bool = True                # Whether to perform gamma correction\n",
    "    gamma_value: float = 1.2                     # Gamma value\n",
    "    sharpen: bool = True                         # Whether to sharpen\n",
    "    adaptive_brightness: bool = True             # Whether to adjust brightness adaptively\n",
    "    brightness_percentile: float = 0.95          # Brightness adjustment percentile\n",
    "    crop_borders: bool = False                   # Whether to crop borders\n",
    "    border_fraction: float = 0.05                # Border crop ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464dd4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePreprocessor:\n",
    "    \"\"\"Part image preprocessing class for enhancing image quality and standardization\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PreprocessingConfig = None):\n",
    "        \"\"\"\n",
    "        Initialize preprocessor\n",
    "        \n",
    "        Args:\n",
    "            config: Preprocessing configuration, uses default if None\n",
    "        \"\"\"\n",
    "        self.config = config or PreprocessingConfig()\n",
    "        self.clahe = cv2.createCLAHE(\n",
    "            clipLimit=self.config.clahe_clip_limit,\n",
    "            tileGridSize=self.config.clahe_grid_size\n",
    "        )\n",
    "        logger.info(f\"Initialized preprocessor with config: {self.config}\")\n",
    "        \n",
    "    def preprocess(self, image: np.ndarray) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Perform a series of preprocessing operations on the input image\n",
    "        \n",
    "        Args:\n",
    "            image: Input BGR format image\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing original and preprocessed images\n",
    "        \"\"\"\n",
    "        if image is None or image.size == 0:\n",
    "            logger.error(\"Received empty image\")\n",
    "            raise ValueError(\"Input image is empty\")\n",
    "            \n",
    "        start_time = time.time()\n",
    "        \n",
    "        logger.info(f\"Starting image processing, shape: {image.shape}\")\n",
    "        result = {\"original\": image.copy()}\n",
    "        \n",
    "        # Record processing steps for debugging and analysis\n",
    "        intermediate_results = {}\n",
    "        \n",
    "        # 1. Crop borders (if enabled)\n",
    "        if self.config.crop_borders:\n",
    "            image = self._crop_borders(image)\n",
    "            intermediate_results[\"after_crop\"] = image.copy()\n",
    "        \n",
    "        # 2. Resize to standard dimensions\n",
    "        image = cv2.resize(image, \n",
    "                         (self.config.target_size[1], self.config.target_size[0]),\n",
    "                         interpolation=cv2.INTER_AREA)\n",
    "        intermediate_results[\"resized\"] = image.copy()\n",
    "        \n",
    "        # 3. Convert to different color spaces for experimentation\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        intermediate_results[\"gray\"] = gray.copy()\n",
    "        intermediate_results[\"hsv\"] = hsv.copy()\n",
    "        \n",
    "        # 4. Adaptive brightness adjustment\n",
    "        if self.config.adaptive_brightness:\n",
    "            image = self._adjust_brightness(image)\n",
    "            intermediate_results[\"brightness_adjusted\"] = image.copy()\n",
    "        \n",
    "        # 5. Contrast enhancement (CLAHE)\n",
    "        enhanced_channels = []\n",
    "        for i in range(3):  # Enhance each BGR channel separately\n",
    "            enhanced_channel = self.clahe.apply(image[:, :, i])\n",
    "            enhanced_channels.append(enhanced_channel)\n",
    "        image = cv2.merge(enhanced_channels)\n",
    "        intermediate_results[\"contrast_enhanced\"] = image.copy()\n",
    "        \n",
    "        # Apply CLAHE to grayscale image as well\n",
    "        gray_enhanced = self.clahe.apply(gray)\n",
    "        intermediate_results[\"gray_enhanced\"] = gray_enhanced.copy()\n",
    "        \n",
    "        # 6. Denoising\n",
    "        image = cv2.fastNlMeansDenoisingColored(\n",
    "            image, None, h=self.config.denoise_h, \n",
    "            hColor=self.config.denoise_h, templateWindowSize=7, searchWindowSize=21\n",
    "        )\n",
    "        intermediate_results[\"denoised\"] = image.copy()\n",
    "        \n",
    "        # 7. Gamma correction (if enabled)\n",
    "        if self.config.gamma_correction:\n",
    "            lookUpTable = self._create_gamma_lut(self.config.gamma_value)\n",
    "            image = cv2.LUT(image, lookUpTable)\n",
    "            intermediate_results[\"gamma_corrected\"] = image.copy()\n",
    "        \n",
    "        # 8. Sharpening (if enabled)\n",
    "        if self.config.sharpen:\n",
    "            kernel = np.array([[-1, -1, -1], \n",
    "                               [-1,  9, -1], \n",
    "                               [-1, -1, -1]])\n",
    "            image = cv2.filter2D(image, -1, kernel)\n",
    "            intermediate_results[\"sharpened\"] = image.copy()\n",
    "        \n",
    "        # 9. Normalization (if enabled)\n",
    "        if self.config.normalize:\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "            intermediate_results[\"normalized\"] = image.copy()\n",
    "        \n",
    "        # Add all intermediate results to output\n",
    "        result[\"preprocessed\"] = image\n",
    "        result[\"gray\"] = gray_enhanced if \"gray_enhanced\" in intermediate_results else gray\n",
    "        result[\"intermediate\"] = intermediate_results\n",
    "        \n",
    "        process_time = time.time() - start_time\n",
    "        logger.info(f\"Preprocessing completed, time: {process_time:.4f} seconds\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _adjust_brightness(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Adaptively adjust image brightness\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            \n",
    "        Returns:\n",
    "            Brightness-adjusted image\n",
    "        \"\"\"\n",
    "        # Calculate image brightness\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        v_channel = hsv[:, :, 2]\n",
    "        \n",
    "        # Calculate current brightness percentile\n",
    "        current_brightness = np.percentile(v_channel, self.config.brightness_percentile * 100)\n",
    "        target_brightness = 220  # Target brightness value (0-255)\n",
    "        \n",
    "        # If brightness is too low, increase it\n",
    "        if current_brightness < target_brightness:\n",
    "            alpha = target_brightness / max(current_brightness, 1)  # Avoid division by zero\n",
    "            alpha = min(alpha, 3.0)  # Limit maximum brightness adjustment factor\n",
    "            \n",
    "            # Adjust brightness\n",
    "            hsv[:, :, 2] = np.clip(v_channel * alpha, 0, 255).astype(np.uint8)\n",
    "            return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def _create_gamma_lut(self, gamma: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Create gamma correction lookup table\n",
    "        \n",
    "        Args:\n",
    "            gamma: Gamma value\n",
    "            \n",
    "        Returns:\n",
    "            Lookup table array of length 255\n",
    "        \"\"\"\n",
    "        lookUpTable = np.empty((1, 256), np.uint8)\n",
    "        for i in range(256):\n",
    "            lookUpTable[0, i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255)\n",
    "        return lookUpTable\n",
    "    \n",
    "    def _crop_borders(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Crop image borders\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            \n",
    "        Returns:\n",
    "            Cropped image\n",
    "        \"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        crop_h = int(h * self.config.border_fraction)\n",
    "        crop_w = int(w * self.config.border_fraction)\n",
    "        \n",
    "        return image[crop_h:h-crop_h, crop_w:w-crop_w]\n",
    "    \n",
    "    def process_batch(self, \n",
    "                     images: List[np.ndarray], \n",
    "                     batch_id: str = None) -> List[Dict[str, np.ndarray]]:\n",
    "        \"\"\"\n",
    "        Process multiple images in batch\n",
    "        \n",
    "        Args:\n",
    "            images: List of images\n",
    "            batch_id: Batch ID for logging\n",
    "            \n",
    "        Returns:\n",
    "            List of processing result dictionaries\n",
    "        \"\"\"\n",
    "        batch_id = batch_id or f\"batch_{int(time.time())}\"\n",
    "        logger.info(f\"Starting batch processing, batch: {batch_id}, image count: {len(images)}\")\n",
    "        \n",
    "        results = []\n",
    "        for i, img in enumerate(images):\n",
    "            try:\n",
    "                logger.info(f\"Processing image {i+1}/{len(images)} batch: {batch_id}\")\n",
    "                result = self.preprocess(img)\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to process image {i+1}: {str(e)}\")\n",
    "                # Add an empty result to maintain index consistency\n",
    "                results.append({\"original\": img, \"error\": str(e)})\n",
    "                \n",
    "        logger.info(f\"Batch {batch_id} processing complete, successful: {sum(1 for r in results if 'error' not in r)}/{len(images)}\")\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ce3c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingPipeline:\n",
    "    \"\"\"\n",
    "    Preprocessing pipeline including image reading, batch processing and result saving\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                config: PreprocessingConfig = None,\n",
    "                input_dir: str = None,\n",
    "                output_dir: str = None):\n",
    "        \"\"\"\n",
    "        Initialize preprocessing pipeline\n",
    "        \n",
    "        Args:\n",
    "            config: Preprocessing configuration\n",
    "            input_dir: Input image directory\n",
    "            output_dir: Output directory for processed results\n",
    "        \"\"\"\n",
    "        self.preprocessor = ImagePreprocessor(config)\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        if self.output_dir:\n",
    "            os.makedirs(self.output_dir, exist_ok=True)\n",
    "            logger.info(f\"Created output directory: {self.output_dir}\")\n",
    "    \n",
    "    def process_file(self, file_path: str, save_result: bool = True) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Process a single image file\n",
    "        \n",
    "        Args:\n",
    "            file_path: Image file path\n",
    "            save_result: Whether to save processing results\n",
    "            \n",
    "        Returns:\n",
    "            Processing result dictionary\n",
    "        \"\"\"\n",
    "        logger.info(f\"Reading file: {file_path}\")\n",
    "        image = cv2.imread(file_path)\n",
    "        \n",
    "        if image is None:\n",
    "            logger.error(f\"Cannot read image: {file_path}\")\n",
    "            raise IOError(f\"Cannot read image file: {file_path}\")\n",
    "        \n",
    "        result = self.preprocessor.preprocess(image)\n",
    "        \n",
    "        if save_result and self.output_dir:\n",
    "            self._save_result(result, file_path)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def process_directory(self, \n",
    "                         directory: str = None, \n",
    "                         batch_size: int = 10,\n",
    "                         file_pattern: str = \"*.png\") -> Dict[str, List[Dict[str, np.ndarray]]]:\n",
    "        \"\"\"\n",
    "        Process all images in a directory\n",
    "        \n",
    "        Args:\n",
    "            directory: Input directory, uses initialized directory if None\n",
    "            batch_size: Batch processing size\n",
    "            file_pattern: File matching pattern\n",
    "            \n",
    "        Returns:\n",
    "            Mapping of batch IDs to result lists\n",
    "        \"\"\"\n",
    "        directory = directory or self.input_dir\n",
    "        if not directory:\n",
    "            logger.error(\"Input directory not specified\")\n",
    "            raise ValueError(\"Input directory not specified\")\n",
    "            \n",
    "        logger.info(f\"Processing directory: {directory}, pattern: {file_pattern}\")\n",
    "        print(f\"Scanning directory: {directory}, looking for files: {file_pattern}\")\n",
    "        \n",
    "        # Check if directory exists\n",
    "        if not os.path.exists(directory):\n",
    "            error_msg = f\"Directory does not exist: {directory}\"\n",
    "            logger.error(error_msg)\n",
    "            print(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "            \n",
    "        # Ensure directory is absolute path\n",
    "        abs_directory = os.path.abspath(directory)\n",
    "        logger.info(f\"Absolute path: {abs_directory}\")\n",
    "        \n",
    "        # List all files in directory\n",
    "        all_files = os.listdir(abs_directory)\n",
    "        logger.info(f\"All files in directory: {all_files}\")\n",
    "        print(f\"Total files in directory: {len(all_files)}\")\n",
    "        \n",
    "        # Use glob to find matching files\n",
    "        files = list(Path(abs_directory).glob(file_pattern))\n",
    "        \n",
    "        if not files:\n",
    "            logger.warning(f\"No files matching {file_pattern} found in directory {directory}\")\n",
    "            # Try other matching patterns to find file types\n",
    "            image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff']\n",
    "            for ext in image_extensions:\n",
    "                test_files = list(Path(abs_directory).glob(f\"*{ext}\"))\n",
    "                if test_files:\n",
    "                    logger.info(f\"Found {len(test_files)} {ext} files\")\n",
    "                    print(f\"Found {len(test_files)} {ext} files, consider using --pattern '*{ext}'\")\n",
    "            return {}\n",
    "            \n",
    "        logger.info(f\"Found {len(files)} matching files: {[f.name for f in files]}\")\n",
    "        \n",
    "        # Process in batches\n",
    "        results = {}\n",
    "        for i in range(0, len(files), batch_size):\n",
    "            batch_files = files[i:i+batch_size]\n",
    "            batch_id = f\"batch_{int(time.time())}_{i//batch_size}\"\n",
    "            \n",
    "            logger.info(f\"Processing batch {batch_id}, file count: {len(batch_files)}\")\n",
    "            \n",
    "            batch_images = []\n",
    "            file_paths = []\n",
    "            \n",
    "            # Read all images in batch\n",
    "            for file_path in batch_files:\n",
    "                try:\n",
    "                    image = cv2.imread(str(file_path))\n",
    "                    if image is not None:\n",
    "                        batch_images.append(image)\n",
    "                        file_paths.append(file_path)\n",
    "                    else:\n",
    "                        logger.warning(f\"Cannot read image: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Failed to read image {file_path}: {str(e)}\")\n",
    "            \n",
    "            # Batch processing\n",
    "            batch_results = self.preprocessor.process_batch(batch_images, batch_id)\n",
    "            \n",
    "            # Save results\n",
    "            if self.output_dir:\n",
    "                for j, (result, file_path) in enumerate(zip(batch_results, file_paths)):\n",
    "                    if \"error\" not in result:\n",
    "                        self._save_result(result, file_path)\n",
    "            \n",
    "            results[batch_id] = batch_results\n",
    "            \n",
    "        return results\n",
    "\n",
    "    def _save_result(self, result: Dict[str, np.ndarray], original_path: Union[str, Path]) -> None:\n",
    "        \"\"\"\n",
    "        Save processing results\n",
    "        \n",
    "        Args:\n",
    "            result: Processing result dictionary\n",
    "            original_path: Original file path\n",
    "        \"\"\"\n",
    "        filename = Path(original_path).stem\n",
    "        output_subdir = os.path.join(self.output_dir, filename)\n",
    "        os.makedirs(output_subdir, exist_ok=True)\n",
    "        \n",
    "        # if \"preprocessed\" in result:\n",
    "        #     preprocessed = result[\"preprocessed\"]\n",
    "            \n",
    "        #     if preprocessed.dtype == np.float32 or preprocessed.dtype == np.float64:\n",
    "        #         preprocessed = (preprocessed * 255).astype(np.uint8)\n",
    "\n",
    "        #     output_path = os.path.join(os.path.dirname(result), f\"{filename}_preprocessed.png\")\n",
    "            \n",
    "        #     cv2.imwrite(str(output_path), preprocessed)\n",
    "        \n",
    "        # Save preprocessed main image\n",
    "        if \"preprocessed\" in result:\n",
    "            preprocessed = result[\"preprocessed\"]\n",
    "            # Convert float image back to uint8\n",
    "            if preprocessed.dtype == np.float32 or preprocessed.dtype == np.float64:\n",
    "                preprocessed = (preprocessed * 255).astype(np.uint8)\n",
    "            \n",
    "            output_path = os.path.join(output_subdir, f\"{filename}_preprocessed.png\")\n",
    "            cv2.imwrite(output_path, preprocessed)\n",
    "        \n",
    "        # Save grayscale image\n",
    "        if \"gray\" in result:\n",
    "            output_path = os.path.join(output_subdir, f\"{filename}_gray.png\")\n",
    "            cv2.imwrite(output_path, result[\"gray\"])\n",
    "        \n",
    "        # Save intermediate results (optional, for debugging)\n",
    "        if \"intermediate\" in result:\n",
    "            for step_name, img in result[\"intermediate\"].items():\n",
    "                # Ensure image is in uint8 format\n",
    "                if img.dtype == np.float32 or img.dtype == np.float64:\n",
    "                    img = (img * 255).astype(np.uint8)\n",
    "                \n",
    "                output_path = os.path.join(output_subdir, f\"{filename}_{step_name}.png\")\n",
    "                cv2.imwrite(output_path, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ae2eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_default_pipeline(input_dir: str = None, \n",
    "                          output_dir: str = None) -> PreprocessingPipeline:\n",
    "    \"\"\"\n",
    "    Create preprocessing pipeline with default configuration\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Input directory\n",
    "        output_dir: Output directory\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessing pipeline instance\n",
    "    \"\"\"\n",
    "    config = PreprocessingConfig(\n",
    "        target_size=(1024, 1024),\n",
    "        normalize=True,\n",
    "        clahe_clip_limit=2.5,\n",
    "        clahe_grid_size=(8, 8),\n",
    "        denoise_h=8,\n",
    "        gamma_correction=True,\n",
    "        gamma_value=1.2,\n",
    "        sharpen=True,\n",
    "        adaptive_brightness=True\n",
    "    )\n",
    "    \n",
    "    return PreprocessingPipeline(config, input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df6e0542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enhanced_pipeline(input_dir: str = None,\n",
    "                           output_dir: str = None) -> PreprocessingPipeline:\n",
    "    \"\"\"\n",
    "    Create enhanced preprocessing pipeline with stronger contrast and sharpening\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Input directory\n",
    "        output_dir: Output directory\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessing pipeline instance\n",
    "    \"\"\"\n",
    "    config = PreprocessingConfig(\n",
    "        target_size=(1280, 1280),  # Higher resolution\n",
    "        normalize=True,\n",
    "        clahe_clip_limit=3.5,      # Stronger contrast\n",
    "        clahe_grid_size=(12, 12),  # Finer grid\n",
    "        denoise_h=7,               # Slightly reduce denoising strength to preserve details\n",
    "        gamma_correction=True,\n",
    "        gamma_value=1.3,           # Slightly increase gamma value\n",
    "        sharpen=True,\n",
    "        adaptive_brightness=True,\n",
    "        brightness_percentile=0.97 # Higher brightness adjustment percentile\n",
    "    )\n",
    "    \n",
    "    return PreprocessingPipeline(config, input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09ac61d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PreprocessingConfig(\n",
    "    target_size=(1024, 1024),\n",
    "    normalize=True,\n",
    "    clahe_clip_limit=2.5,\n",
    "    clahe_grid_size=(8, 8),\n",
    "    denoise_h=8,\n",
    "    gamma_correction=True,\n",
    "    gamma_value=1.2,\n",
    "    sharpen=True,\n",
    "    adaptive_brightness=True\n",
    ")\n",
    "\n",
    "input_dir = \"data/train\"\n",
    "output_dir = \"data/train_preprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5454ad26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 16:09:51,178 - PreprocessingModule - INFO - Initialized preprocessor with config: PreprocessingConfig(target_size=(1024, 1024), normalize=True, clahe_clip_limit=2.5, clahe_grid_size=(8, 8), denoise_h=8, gamma_correction=True, gamma_value=1.2, sharpen=True, adaptive_brightness=True, brightness_percentile=0.95, crop_borders=False, border_fraction=0.05)\n",
      "2025-05-19 16:09:51,180 - PreprocessingModule - INFO - Created output directory: data/train_preprocessed\n"
     ]
    }
   ],
   "source": [
    "pipeline = PreprocessingPipeline(config, input_dir, output_dir)\n",
    "batch = 10\n",
    "pattern=\"*.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "138d7c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 16:49:15,119 - PreprocessingModule - INFO - Processing directory: data/train, batch size: 10\n",
      "2025-05-19 16:49:15,120 - PreprocessingModule - INFO - Processing directory: data/train, pattern: *.png\n",
      "2025-05-19 16:49:15,121 - PreprocessingModule - INFO - Absolute path: d:\\aiml\\defect_detector\\data\\train\n",
      "2025-05-19 16:49:15,121 - PreprocessingModule - INFO - All files in directory: ['Picture1.png', 'Picture2.png', 'Picture3.png', 'Picture4.png', 'Picture5.png', 'Picture6.png', 'Picture7.png', 'Picture8.png']\n",
      "2025-05-19 16:49:15,121 - PreprocessingModule - INFO - Found 8 matching files: ['Picture1.png', 'Picture2.png', 'Picture3.png', 'Picture4.png', 'Picture5.png', 'Picture6.png', 'Picture7.png', 'Picture8.png']\n",
      "2025-05-19 16:49:15,121 - PreprocessingModule - INFO - Processing batch batch_1747644555_0, file count: 8\n",
      "2025-05-19 16:49:15,149 - PreprocessingModule - INFO - Starting batch processing, batch: batch_1747644555_0, image count: 8\n",
      "2025-05-19 16:49:15,149 - PreprocessingModule - INFO - Processing image 1/8 batch: batch_1747644555_0\n",
      "2025-05-19 16:49:15,149 - PreprocessingModule - INFO - Starting image processing, shape: (419, 468, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory: data/train, looking for files: *.png\n",
      "Total files in directory: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 16:49:17,914 - PreprocessingModule - INFO - Preprocessing completed, time: 2.7647 seconds\n",
      "2025-05-19 16:49:17,929 - PreprocessingModule - INFO - Processing image 2/8 batch: batch_1747644555_0\n",
      "2025-05-19 16:49:17,931 - PreprocessingModule - INFO - Starting image processing, shape: (248, 273, 3)\n",
      "2025-05-19 16:49:20,884 - PreprocessingModule - INFO - Preprocessing completed, time: 2.9534 seconds\n",
      "2025-05-19 16:49:20,884 - PreprocessingModule - INFO - Processing image 3/8 batch: batch_1747644555_0\n",
      "2025-05-19 16:49:20,884 - PreprocessingModule - INFO - Starting image processing, shape: (280, 304, 3)\n",
      "2025-05-19 16:49:23,871 - PreprocessingModule - INFO - Preprocessing completed, time: 2.9869 seconds\n",
      "2025-05-19 16:49:23,875 - PreprocessingModule - INFO - Processing image 4/8 batch: batch_1747644555_0\n",
      "2025-05-19 16:49:23,881 - PreprocessingModule - INFO - Starting image processing, shape: (328, 341, 3)\n",
      "2025-05-19 16:49:26,800 - PreprocessingModule - INFO - Preprocessing completed, time: 2.9184 seconds\n",
      "2025-05-19 16:49:26,800 - PreprocessingModule - INFO - Processing image 5/8 batch: batch_1747644555_0\n",
      "2025-05-19 16:49:26,800 - PreprocessingModule - INFO - Starting image processing, shape: (199, 211, 3)\n",
      "2025-05-19 16:49:29,935 - PreprocessingModule - INFO - Preprocessing completed, time: 3.1350 seconds\n",
      "2025-05-19 16:49:29,935 - PreprocessingModule - INFO - Processing image 6/8 batch: batch_1747644555_0\n",
      "2025-05-19 16:49:29,935 - PreprocessingModule - INFO - Starting image processing, shape: (202, 196, 3)\n",
      "2025-05-19 16:49:33,072 - PreprocessingModule - INFO - Preprocessing completed, time: 3.1376 seconds\n",
      "2025-05-19 16:49:33,072 - PreprocessingModule - INFO - Processing image 7/8 batch: batch_1747644555_0\n",
      "2025-05-19 16:49:33,072 - PreprocessingModule - INFO - Starting image processing, shape: (177, 232, 3)\n",
      "2025-05-19 16:49:36,110 - PreprocessingModule - INFO - Preprocessing completed, time: 3.0381 seconds\n",
      "2025-05-19 16:49:36,110 - PreprocessingModule - INFO - Processing image 8/8 batch: batch_1747644555_0\n",
      "2025-05-19 16:49:36,116 - PreprocessingModule - INFO - Starting image processing, shape: (212, 200, 3)\n",
      "2025-05-19 16:49:39,277 - PreprocessingModule - INFO - Preprocessing completed, time: 3.1612 seconds\n",
      "2025-05-19 16:49:39,292 - PreprocessingModule - INFO - Batch batch_1747644555_0 processing complete, successful: 8/8\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, batch size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m results = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_pattern\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpattern\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing completed, total \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mbatch\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mresults.values())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m files\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 136\u001b[39m, in \u001b[36mPreprocessingPipeline.process_directory\u001b[39m\u001b[34m(self, directory, batch_size, file_pattern)\u001b[39m\n\u001b[32m    134\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m j, (result, file_path) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(batch_results, file_paths)):\n\u001b[32m    135\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m                 \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m     results[batch_id] = batch_results\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 198\u001b[39m, in \u001b[36mPreprocessingPipeline._save_result\u001b[39m\u001b[34m(self, result, original_path)\u001b[39m\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m preprocessed.dtype == np.float32 \u001b[38;5;129;01mor\u001b[39;00m preprocessed.dtype == np.float64:\n\u001b[32m    196\u001b[39m         preprocessed = (preprocessed * \u001b[32m255\u001b[39m).astype(np.uint8)\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     output_path = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_subdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_preprocessed.png\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m     cv2.imwrite(output_path, preprocessed)\n\u001b[32m    201\u001b[39m \u001b[38;5;66;03m# Save grayscale image\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Processing directory: {input_dir}, batch size: {batch}\")\n",
    "results = pipeline.process_directory(\n",
    "    str(input_dir), batch_size=batch, file_pattern=pattern\n",
    ")\n",
    "logger.info(f\"Processing completed, total {sum(len(batch) for batch in results.values())} files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_skc_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
