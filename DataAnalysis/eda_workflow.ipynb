{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/datav1.csv'  \n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# 指定了 parse_dates 参数来解析 TIME 列中的日期数据。\n",
    "df_date = pd.read_csv('data/data.csv', parse_dates=['TIME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 显示数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  # 显示所有行\n",
    "pd.set_option('display.max_columns', None)  # 显示所有列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 禁用科学计数法\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存CSV 文件\n",
    "df.to_csv('data/data_1prewash.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看数据的分布情况，overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_overview(df):\n",
    "    \"\"\"提供数据的基本概览\"\"\"\n",
    "    print(\"\\n======== 数据基本信息 ========\")\n",
    "    print(f\"数据行数: {df.shape[0]}\")\n",
    "    print(f\"数据列数: {df.shape[1]}\")\n",
    "    \n",
    "    # 数据类型摘要\n",
    "    dtypes = df.dtypes.value_counts()\n",
    "    print(\"\\n数据类型分布:\")\n",
    "    for dtype, count in dtypes.items():\n",
    "        print(f\"- {dtype}: {count}列\")\n",
    "    \n",
    "    # 查看数据前5行\n",
    "    print(\"\\n数据前5行预览:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    # 显示列信息\n",
    "    print(\"\\n列信息:\")\n",
    "    column_info = pd.DataFrame({\n",
    "        '数据类型': df.dtypes,\n",
    "        '非空值数量': df.count(),\n",
    "        '空值数量': df.isnull().sum(),\n",
    "        '空值百分比': (df.isnull().sum() / len(df) * 100).round(2),\n",
    "        '唯一值数量': df.nunique(),\n",
    "        '唯一值': {column: df[column].unique() for column in df.columns}\n",
    "    })\n",
    "    column_info['空值百分比'] = column_info['空值百分比'].astype(str) + '%'\n",
    "    display(column_info)\n",
    "    \n",
    "    # 基本统计信息,结果格式化为两位小数\n",
    "    print(\"\\n数值列的统计描述:\")\n",
    "    display(df.describe().T.style.format(\"{:.2f}\"))\n",
    "\n",
    "    # 分类列的统计描述\n",
    "    cat_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "    if not cat_columns.empty:\n",
    "        print(\"\\n分类列的统计描述:\")\n",
    "        cat_stats = pd.DataFrame({\n",
    "            '唯一值数量': df[cat_columns].nunique(),\n",
    "            '最常见值': [df[col].value_counts().index[0] if not df[col].value_counts().empty else None for col in cat_columns],\n",
    "            '最常见值频次': [df[col].value_counts().iloc[0] if not df[col].value_counts().empty else 0 for col in cat_columns],\n",
    "            '最常见值占比': [(df[col].value_counts().iloc[0] / df[col].count() * 100).round(2) if not df[col].value_counts().empty else 0 for col in cat_columns]\n",
    "        })\n",
    "        cat_stats['最常见值占比'] = cat_stats['最常见值占比'].astype(str) + '%'\n",
    "        display(cat_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数值型数据分析结果查看\n",
    "# count: 数据集中元素的数量。\n",
    "# mean: 数据的平均值。\n",
    "# std: 标准差，表示数据的分散程度。\n",
    "# min: 数据中的最小值。\n",
    "# 25%: 第一四分位数，表示数据中25%的值小于或等于这个值。\n",
    "# 50%: 中位数，表示数据中50%的值小于或等于这个值。\n",
    "# 75%: 第三四分位数，表示数据中75%的值小于或等于这个值。\n",
    "# max: 数据中的最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 某个数值型数据列的数据分布情况\n",
    "def show_value_counts(series):\n",
    "    value_counts = series.value_counts()\n",
    "    \n",
    "    print(f\"值统计：\")\n",
    "    print(value_counts)\n",
    "    print(f\"\\n共有 {len(value_counts)} 个不同的值\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.pie(value_counts.values, \n",
    "            labels=[f'{label}\\n({count}个)' for label, count in zip(value_counts.index, value_counts.values)],\n",
    "            autopct='%1.1f%%',\n",
    "            colors=['lightblue', 'lightgreen', 'lightcoral', 'wheat'],  # 自定义颜色\n",
    "            explode=[0.1] * len(value_counts),  # 扇形分离效果\n",
    "            shadow=True)  # 添加阴影\n",
    "    plt.title('数据分布饼图')\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "    missing_cols = df.columns[df.isnull().any()].tolist()\n",
    "    \n",
    "    if not missing_cols:\n",
    "        print(\"数据中没有缺失值，无需处理。\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"\\n======== 缺失值处理 ========\")\n",
    "    print(f\"发现以下{len(missing_cols)}列含有缺失值:\")\n",
    "    \n",
    "    for col in missing_cols:\n",
    "        missing_pct = (df[col].isnull().sum() / len(df) * 100).round(2)\n",
    "        print(f\"- {col}: {df[col].isnull().sum()}个缺失值 ({missing_pct}%)\")\n",
    "    \n",
    "    strategies = {\n",
    "        '删除': '删除含有缺失值的行',\n",
    "        '均值填充': '对数值列使用均值填充',\n",
    "        '中位数填充': '对数值列使用中位数填充',\n",
    "        '众数填充': '对分类列使用众数填充',\n",
    "        '0填充': '使用0填充缺失值',\n",
    "        '指定值填充': '使用指定的值填充缺失值',\n",
    "        '不处理': '保留缺失值不做处理'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n可用的缺失值处理策略:\")\n",
    "    for key, desc in strategies.items():\n",
    "        print(f\"- {key}: {desc}\")\n",
    "    \n",
    "    strategy = input(\"\\n请选择缺失值处理策略 (默认为不处理): \") or '不处理'\n",
    "    \n",
    "    if strategy not in strategies:\n",
    "        print(f\"未知策略: {strategy}，将默认不处理缺失值。\")\n",
    "        return df\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    if strategy == '删除':\n",
    "        df_clean = df.dropna()\n",
    "        print(f\"已删除含有缺失值的行，数据形状从 {df.shape} 变为 {df_clean.shape}\")\n",
    "    \n",
    "    elif strategy == '均值填充':\n",
    "        for col in missing_cols:\n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                df_clean[col] = df[col].fillna(df[col].mean())\n",
    "                print(f\"已对列 '{col}' 使用均值 {df[col].mean():.2f} 填充\")\n",
    "            else:\n",
    "                print(f\"列 '{col}' 不是数值类型，跳过均值填充\")\n",
    "    \n",
    "    elif strategy == '中位数填充':\n",
    "        for col in missing_cols:\n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                df_clean[col] = df[col].fillna(df[col].median())\n",
    "                print(f\"已对列 '{col}' 使用中位数 {df[col].median():.2f} 填充\")\n",
    "            else:\n",
    "                print(f\"列 '{col}' 不是数值类型，跳过中位数填充\")\n",
    "    \n",
    "    elif strategy == '众数填充':\n",
    "        for col in missing_cols:\n",
    "            mode_value = df[col].mode()[0]\n",
    "            df_clean[col] = df[col].fillna(mode_value)\n",
    "            print(f\"已对列 '{col}' 使用众数 '{mode_value}' 填充\")\n",
    "    \n",
    "    elif strategy == '0填充':\n",
    "        for col in missing_cols:\n",
    "            df_clean[col] = df[col].fillna(0)\n",
    "            print(f\"已对列 '{col}' 使用0填充\")\n",
    "    \n",
    "    elif strategy == '指定值填充':\n",
    "        for col in missing_cols:\n",
    "            fill_value = input(f\"请输入用于填充列 '{col}' 的值: \")\n",
    "            # 尝试转换为原始列的数据类型\n",
    "            try:\n",
    "                if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                    fill_value = float(fill_value)\n",
    "                df_clean[col] = df[col].fillna(fill_value)\n",
    "                print(f\"已对列 '{col}' 使用 '{fill_value}' 填充\")\n",
    "            except:\n",
    "                print(f\"无法将 '{fill_value}' 转换为合适的类型，跳过此列\")\n",
    "    \n",
    "    elif strategy == '不处理':\n",
    "        print(\"保留缺失值不做处理\")\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df):\n",
    "    \"\"\"检测并处理数据中的异常值\"\"\"\n",
    "    print(\"\\n======== 异常值检测与处理 ========\")\n",
    "    \n",
    "    # 只对数值列进行异常值检测\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "    \n",
    "    if not numeric_cols:\n",
    "        print(\"数据中没有数值列，无法检测异常值。\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"使用IQR方法检测异常值 (数值列: {len(numeric_cols)}列)\")\n",
    "    \n",
    "    outliers_summary = {}\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
    "        outlier_pct = round((len(outliers) / len(df) * 100), 2)\n",
    "        \n",
    "        if not outliers.empty:\n",
    "            outliers_summary[col] = {\n",
    "                'count': len(outliers),\n",
    "                'percentage': outlier_pct,\n",
    "                'lower_bound': lower_bound,\n",
    "                'upper_bound': upper_bound\n",
    "            }\n",
    "    \n",
    "    if not outliers_summary:\n",
    "        print(\"未检测到异常值。\")\n",
    "        return df\n",
    "    \n",
    "    print(\"\\n检测到以下列存在异常值:\")\n",
    "    for col, stats in outliers_summary.items():\n",
    "        print(f\"- {col}: {stats['count']}个异常值 ({stats['percentage']}%), 范围: [{stats['lower_bound']:.2f}, {stats['upper_bound']:.2f}]\")\n",
    "    \n",
    "    # 绘制箱线图来展示异常值\n",
    "    n_cols = min(3, len(outliers_summary))\n",
    "    n_rows = (len(outliers_summary) + n_cols - 1) // n_cols\n",
    "    \n",
    "    plt.figure(figsize=(n_cols*5, n_rows*4))\n",
    "    for i, col in enumerate(outliers_summary.keys()):\n",
    "        plt.subplot(n_rows, n_cols, i+1)\n",
    "        sns.boxplot(x=df[col])\n",
    "        plt.title(f\"{col}的箱线图\")\n",
    "        plt.tight_layout()\n",
    "    plt.savefig('images/outliers_boxplot.png')\n",
    "    plt.show()\n",
    "    \n",
    "    strategies = {\n",
    "        '删除': '删除含有异常值的行',\n",
    "        '替换为上下界': '将异常值替换为上下界值',\n",
    "        '替换为均值': '将异常值替换为均值',\n",
    "        '替换为中位数': '将异常值替换为中位数',\n",
    "        '不处理': '保留异常值不做处理'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n可用的异常值处理策略:\")\n",
    "    for key, desc in strategies.items():\n",
    "        print(f\"- {key}: {desc}\")\n",
    "    \n",
    "    strategy = input(\"\\n请选择异常值处理策略 (默认为不处理): \") or '不处理'\n",
    "    \n",
    "    if strategy not in strategies:\n",
    "        print(f\"未知策略: {strategy}，将默认不处理异常值。\")\n",
    "        return df\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    if strategy == '删除':\n",
    "        original_shape = df_clean.shape\n",
    "        for col in outliers_summary.keys():\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "        \n",
    "        print(f\"已删除含有异常值的行，数据形状从 {original_shape} 变为 {df_clean.shape}\")\n",
    "    \n",
    "    elif strategy == '替换为上下界':\n",
    "        for col in outliers_summary.keys():\n",
    "            stats = outliers_summary[col]\n",
    "            lower_bound = stats['lower_bound']\n",
    "            upper_bound = stats['upper_bound']\n",
    "            \n",
    "            # 将小于下界的值替换为下界值\n",
    "            df_clean.loc[df_clean[col] < lower_bound, col] = lower_bound\n",
    "            # 将大于上界的值替换为上界值\n",
    "            df_clean.loc[df_clean[col] > upper_bound, col] = upper_bound\n",
    "            \n",
    "            print(f\"已将 '{col}' 列的异常值替换为上下界: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "    \n",
    "    elif strategy == '替换为均值':\n",
    "        for col in outliers_summary.keys():\n",
    "            stats = outliers_summary[col]\n",
    "            lower_bound = stats['lower_bound']\n",
    "            upper_bound = stats['upper_bound']\n",
    "            mean_value = df[col].mean()\n",
    "            \n",
    "            # 替换异常值为均值\n",
    "            mask = (df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)\n",
    "            df_clean.loc[mask, col] = mean_value\n",
    "            \n",
    "            print(f\"已将 '{col}' 列的异常值替换为均值: {mean_value:.2f}\")\n",
    "    \n",
    "    elif strategy == '替换为中位数':\n",
    "        for col in outliers_summary.keys():\n",
    "            stats = outliers_summary[col]\n",
    "            lower_bound = stats['lower_bound']\n",
    "            upper_bound = stats['upper_bound']\n",
    "            median_value = df[col].median()\n",
    "            \n",
    "            # 替换异常值为中位数\n",
    "            mask = (df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)\n",
    "            df_clean.loc[mask, col] = median_value\n",
    "            \n",
    "            print(f\"已将 '{col}' 列的异常值替换为中位数: {median_value:.2f}\")\n",
    "    \n",
    "    elif strategy == '不处理':\n",
    "        print(\"保留异常值不做处理\")\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 删除不需要的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_useless_columns(df):\n",
    "    \n",
    "    # 丢弃唯一值数量为 1 的列\n",
    "    unique_counts = df.nunique()\n",
    "    columns_to_drop = unique_counts[unique_counts == 1].index\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    # 丢弃 全部为NaN 的列\n",
    "    columns_to_drop = df.columns[df.isna().all()]\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    # 丢弃object 类型的列\n",
    "    object_columns = df.select_dtypes(include=['object']).columns\n",
    "    df = df.drop(columns=object_columns)\n",
    "\n",
    "    # 丢弃 datetime64[ns] 类型的列\n",
    "    datetime_columns = df.select_dtypes(include=['datetime64[ns]']).columns\n",
    "    df = df.drop(columns=datetime_columns)\n",
    "\n",
    "    # 丢弃第 5 到第 11 列（索引从 0 开始，第 5 列的索引是 4，第 11 列的索引是 10）。\n",
    "    df = df.drop(df.columns[4:11], axis=1)\n",
    "    # 丢弃第 6 到第 10 列（索引从 0 开始，第 6 列的索引是 5，第 10 列的索引是 9）。\n",
    "    df = df.drop(df.columns[5:10], axis=1)\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 改变列名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.rename(columns={\n",
    "    'plc0': 'c_pv_prewash', \n",
    "    'plc6': 'c_sp_prewash', \n",
    "    'plc1': 'c_pv_regeneration', \n",
    "    'plc2': 'c_pv_regeneration_oil_in', \n",
    "    'plc3': 'c_pv_regeneration_oil_out', \n",
    "    'plc5': 'mv_pv_prewash', \n",
    "    'plc4': 'c_pv_rinse',\n",
    "    'plc7': 'c_sp_rinse',\n",
    "    'plc8': 'pa_vacuum_dry',\n",
    "    'plc9': 'kpa_prewash'\n",
    "    })\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "df1.to_csv('data/data_1prewash.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征变换\n",
    "\n",
    "对于某些带有数学参数的项进行特征变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer, FunctionTransformer\n",
    "import numpy as np\n",
    "\n",
    "# 对数变换 - 处理偏斜数据\n",
    "df['log_列名'] = np.log1p(df['列名'])  # log1p = log(1+x)\n",
    "\n",
    "# Box-Cox变换 - 使数据更接近正态分布\n",
    "pt = PowerTransformer(method='box-cox')\n",
    "df['boxcox_列名'] = pt.fit_transform(df[['列名']])\n",
    "\n",
    "# 平方根变换\n",
    "df['sqrt_列名'] = np.sqrt(df['列名'])\n",
    "\n",
    "# 立方根变换\n",
    "df['cbrt_列名'] = np.cbrt(df['列名'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征分箱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 等宽分箱\n",
    "df['等宽分箱'] = pd.qcut(df['列名'], q=10, labels=False)\n",
    "\n",
    "# 等频分箱\n",
    "df['等频分箱'] = pd.cut(df['列名'], bins=10, labels=False)\n",
    "\n",
    "# 自定义分箱\n",
    "bins = [0, 18, 35, 50, 65, 100]\n",
    "labels = ['青少年', '青年', '中年', '中老年', '老年']\n",
    "df['年龄分组'] = pd.cut(df['年龄'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征交互"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建多项式特征\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_features = poly.fit_transform(df[['特征1', '特征2']])\n",
    "\n",
    "# 基本数学运算\n",
    "df['特征1_乘_特征2'] = df['特征1'] * df['特征2']\n",
    "df['特征1_加_特征2'] = df['特征1'] + df['特征2']\n",
    "df['特征1_除_特征2'] = df['特征1'] / df['特征2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据平衡（对于分类问题）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# 过采样\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# 欠采样\n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = under_sampler.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 类别数据 编码处理\n",
    "\n",
    "使用情景：\n",
    "* 如果类别之间有顺序关系（如：小、中、大），可以使用序数编码\n",
    "* 如果类别之间没有顺序关系，通常使用独热编码\n",
    "* 如果类别数量很多，可以考虑使用频率编码或目标编码\n",
    "* 如果需要保持数据的简单性，可以使用标签编码\n",
    "\n",
    "注意事项：\n",
    "* 处理缺失值：在编码之前，需要先处理缺失值\n",
    "* 新类别处理：在测试集中可能出现训练集中没有的类别，需要考虑如何处理\n",
    "* 维度灾难：使用独热编码时，如果类别太多，可能会导致特征维度剧增"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签编码 (Label Encoding)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 创建编码器\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# 假设我们有一列类别数据\n",
    "categories = ['红色', '蓝色', '绿色', '红色', '蓝色']\n",
    "\n",
    "# 进行编码\n",
    "encoded_categories = label_encoder.fit_transform(categories)\n",
    "# 结果会是: [2, 0, 1, 2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 独热编码 (One-Hot Encoding)\n",
    "import pandas as pd\n",
    "\n",
    "# 假设我们有一个DataFrame\n",
    "df = pd.DataFrame({\n",
    "    '颜色': ['红色', '蓝色', '绿色', '红色', '蓝色']\n",
    "})\n",
    "\n",
    "# 使用pandas的get_dummies进行独热编码\n",
    "encoded_df = pd.get_dummies(df['颜色'])\n",
    "\n",
    "# 结果是\n",
    "#       红色     绿色     蓝色\n",
    "# 0   True  False  False\n",
    "# 1  False  False   True\n",
    "# 2  False   True  False\n",
    "# 3   True  False  False\n",
    "# 4  False  False   True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 序数编码 (Ordinal Encoding)\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# 创建编码器\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# 对于有顺序意义的类别（比如：小，中，大）\n",
    "categories = [['小', '中', '大']]\n",
    "ordinal_encoder.fit([['小'], ['中'], ['大']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 频率编码 (Frequency Encoding)\n",
    "\n",
    "def frequency_encode(data):\n",
    "    # 计算每个类别的频率\n",
    "    freq_encoding = data.value_counts(normalize=True).to_dict()\n",
    "    return data.map(freq_encoding)\n",
    "\n",
    "# 使用示例\n",
    "df['颜色_freq'] = frequency_encode(df['颜色'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目标编码 (Target Encoding)\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# 创建编码器\n",
    "target_encoder = TargetEncoder()\n",
    "\n",
    "# 假设X是特征（类别列），y是目标变量\n",
    "X_encoded = target_encoder.fit_transform(X, y)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换二元数据为targe编码，保存为target列\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def target_encoded(df):\n",
    "    le = LabelEncoder()\n",
    "    df['target'] = le.fit_transform(df['acnc'])\n",
    "    print(\"类别编码对应关系：\")\n",
    "    for i, label in enumerate(le.classes_):\n",
    "        print(f\"{label} -> {i}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 时间序列分析：\n",
    "\n",
    "趋势分析： 绘制时间序列图，观察生产指标随时间的变化趋势。\n",
    "\n",
    "季节性分析： 识别数据中的周期性模式，例如每日、每周或每月的波动。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可能需要处理时区\n",
    "\n",
    "* 如果需要进行时间序列预测，通常需要提取周期性特征\n",
    "* 如果是做分类任务，可能需要将时间转换为分类特征\n",
    "* 如果要分析趋势，可能需要使用滑动窗口特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 使用 Pandas 转换时间格式\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 将字符串转换为datetime格式\n",
    "df['时间列'] = pd.to_datetime(df['时间列'])\n",
    "\n",
    "# 如果数据格式特殊，可以指定格式\n",
    "df['时间列'] = pd.to_datetime(df['时间列'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 提取时间特征\n",
    "\n",
    "# 假设df['时间列']已经是datetime格式\n",
    "df['年'] = df['时间列'].dt.year\n",
    "df['月'] = df['时间列'].dt.month\n",
    "df['日'] = df['时间列'].dt.day\n",
    "df['星期'] = df['时间列'].dt.dayofweek  # 0-6，0代表周一\n",
    "df['小时'] = df['时间列'].dt.hour\n",
    "df['分钟'] = df['时间列'].dt.minute\n",
    "df['是否周末'] = df['时间列'].dt.dayofweek.isin([5,6]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 时间差计算\n",
    "\n",
    "# 计算两个时间之间的差值\n",
    "df['时间差'] = df['时间列'] - df['时间列'].shift(1)\n",
    "\n",
    "# 转换时间差为具体数值（如天数、小时数等）\n",
    "df['天数差'] = df['时间差'].dt.days\n",
    "df['小时差'] = df['时间差'].dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 时间周期特征\n",
    "\n",
    "# 季节编码\n",
    "df['季节'] = df['时间列'].dt.quarter\n",
    "\n",
    "# 月份的正弦和余弦转换（循环特征）\n",
    "df['月份_sin'] = np.sin(2 * np.pi * df['时间列'].dt.month/12)\n",
    "df['月份_cos'] = np.cos(2 * np.pi * df['时间列'].dt.month/12)\n",
    "\n",
    "# 小时的周期性特征\n",
    "df['小时_sin'] = np.sin(2 * np.pi * df['时间列'].dt.hour/24)\n",
    "df['小时_cos'] = np.cos(2 * np.pi * df['时间列'].dt.hour/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 时间窗口统计\n",
    "\n",
    "# 按照时间窗口进行重采样\n",
    "# 每小时统计\n",
    "hourly_stats = df.resample('H', on='时间列').mean()\n",
    "\n",
    "# 每天统计\n",
    "daily_stats = df.resample('D', on='时间列').mean()\n",
    "\n",
    "# 每月统计\n",
    "monthly_stats = df.resample('M', on='时间列').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置时区\n",
    "df['时间列'] = df['时间列'].dt.tz_localize('UTC')\n",
    "# 转换时区\n",
    "df['时间列'] = df['时间列'].dt.tz_convert('Asia/Shanghai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 滑动窗口特征\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据标准化/归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 常用的可视化图表\n",
    "\n",
    "折线图： 展示变量随时间的变化趋势。\n",
    "\n",
    "散点图矩阵： 同时展示多个变量之间的两两关系。\n",
    "\n",
    "箱线图： 比较不同条件下数据的分布和离群点。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单变量分析\n",
    "\n",
    "分析数值变量： 计算均值、中位数、标准差等描述性统计量。​\n",
    "- 计算均值、中位数、标准差等描述性统计量，并绘制直方图或箱线图，了解数据分布情况。​\n",
    "\n",
    "分析分类变量： 计算频率分布，了解各类别的分布情况。\n",
    "- 计算频率分布，绘制条形图或饼图，了解各类别的分布情况。   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 双变量分析\n",
    "\n",
    "数值变量之间： 使用散点图和计算相关系数，探讨变量之间的线性关系。\n",
    "\n",
    "数值与分类变量之间： 通过箱线图或小提琴图，比较不同类别下数值变量的分布差异。\n",
    "\n",
    "分类变量之间： 构建列联表，使用堆积条形图展示类别之间的关系。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多变量分析：\n",
    "\n",
    "热力图： 展示多个变量之间的相关性矩阵，识别潜在的相关关系。\n",
    "\n",
    "主成分分析（PCA）： 将高维数据降维，识别主要影响因素，便于可视化和后续分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据相关性系数可视化相关性热力图（Correlation Heatmap）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相关性系数（Correlation Coefficient）的取值范围是[−1,1]，其含义如下：\n",
    "* 1：完全正相关，表示两列的变化方向完全一致。\n",
    "* -1：完全负相关，表示两列的变化方向完全相反。\n",
    "* 0：无相关性，表示两列之间没有线性关系。\n",
    "\n",
    "热力图的颜色\n",
    "* 颜色深浅：颜色越深（通常为红色），表示相关性越强；颜色越浅（通常为蓝色），表示相关性越弱。\n",
    "* 颜色方向：红色通常表示正相关，蓝色通常表示负相关。\n",
    "\n",
    "对角线\n",
    "* 热力图的对角线通常是深色的，因为每列与自身的相关性为 1。\n",
    "\n",
    "解读步骤\n",
    "\n",
    "* 强相关性：\n",
    "寻找颜色较深的区域，这些区域对应的列之间相关性较强。\n",
    "* 弱相关性：\n",
    "寻找颜色较浅的区域，这些区域对应的列之间相关性较弱。\n",
    "* 负相关性：\n",
    "寻找蓝色区域，这些区域对应的列之间负相关。\n",
    "* 无相关性：\n",
    "寻找接近白色的区域，这些区域对应的列之间无相关性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def correlation_heat_map(df):\n",
    "    correlation_matrix = df.corr()\n",
    "    # 根据结果适量调整图表大小\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.title('Correlation Heatmap')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准化之后做PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化数据\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 初始化 PCA，设置降维后的维度\n",
    "pca = PCA(n_components=2)  # 降维到 2 维\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 解释 PCA 结果\n",
    "print(\"降维后的数据形状:\", X_pca.shape)\n",
    "print(\"每个主成分解释的方差比例:\", pca.explained_variance_ratio_)\n",
    "print(\"主成分的方向:\\n\", pca.components_)\n",
    "\n",
    "# 可视化降维结果\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1])\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('PCA Result')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
