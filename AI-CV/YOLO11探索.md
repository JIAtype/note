è¦å¿«é€Ÿå¼€å§‹ä½¿ç”¨ YOLO11 è¿›è¡Œæœ¬åœ°æ•°æ®å¾®è°ƒï¼ˆå¦‚é›¶ä»¶è¡¨é¢ç‘•ç–µæ£€æµ‹ï¼‰ï¼Œå¯å‚è€ƒä»¥ä¸‹æ­¥éª¤ï¼š

1. å‡†å¤‡ä½ çš„æœ¬åœ°æ•°æ®é›†ï¼Œæ ‡æ³¨å¥½ç›®æ ‡ï¼ˆå¦‚è¡¨é¢ç‘•ç–µï¼‰ç±»åˆ«å’Œä½ç½®ï¼Œæ•°æ®æ ¼å¼éœ€ç¬¦åˆ YOLO è¦æ±‚ï¼ˆå¯ç”¨ coco8.yaml ä½œä¸ºå‚è€ƒï¼‰[(1)](https://docs.ultralytics.com/models/yolo11)[(2)](https://docs.ultralytics.com/guides/azureml-quickstart)ã€‚
2. å®‰è£… Ultralytics åŒ…ï¼š

```bash
pip install ultralytics
```
[(1)](https://docs.ultralytics.com/models/yolo11)[(2)](https://docs.ultralytics.com/guides/azureml-quickstart)

3. åœ¨ Python è„šæœ¬ä¸­åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å¹¶è¿›è¡Œå¾®è°ƒï¼Œä¾‹å¦‚ï¼š

```python
from ultralytics import YOLO
# åŠ è½½ COCO é¢„è®­ç»ƒ YOLO11n æ¨¡å‹
model = YOLO("yolo11n.pt")
# ç”¨æœ¬åœ°æ•°æ®é›†è®­ç»ƒæ¨¡å‹ï¼Œè®¾ç½®è®­ç»ƒè½®æ•°å’Œå›¾ç‰‡å°ºå¯¸
results = model.train(data="ä½ çš„æ•°æ®é›†.yaml", epochs=100, imgsz=640)
```
[(1)](https://docs.ultralytics.com/models/yolo11)[(2)](https://docs.ultralytics.com/guides/azureml-quickstart)

4. è®­ç»ƒå®Œæˆåï¼Œå¯ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹å’Œè¯„ä¼°ï¼š

```python
results = model("ä½ çš„æµ‹è¯•å›¾ç‰‡.jpg")
results[0].show()
```
[(1)](https://docs.ultralytics.com/models/yolo11)[(2)](https://docs.ultralytics.com/guides/azureml-quickstart)

5. ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨å‘½ä»¤è¡Œæ–¹å¼è®­ç»ƒå’Œæ¨ç†ï¼š

```bash
yolo train model=yolo11n.pt data=ä½ çš„æ•°æ®é›†.yaml epochs=100 imgsz=640
yolo predict model=yolo11n.pt source=ä½ çš„æµ‹è¯•å›¾ç‰‡.jpg
```
[(1)](https://docs.ultralytics.com/models/yolo11)[(2)](https://docs.ultralytics.com/guides/azureml-quickstart)

è¯¦ç»†æ–‡æ¡£ä¸æ›´å¤šç¤ºä¾‹å¯å‚è€ƒï¼š[YOLO11å®˜æ–¹æ–‡æ¡£](https://docs.ultralytics.com/models/yolo11/)  
æ•°æ®é›†æ ¼å¼å‚è€ƒï¼š[æ•°æ®é›†é…ç½®è¯´æ˜](https://docs.ultralytics.com/datasets/detect/)
[YOLO11 ğŸš€ on AzureML](https://docs.ultralytics.com/guides/azureml-quickstart/)

---

# Fine-tuningYOLO

æˆ‘æ¥å¸®ä½ å®ç°ç”¨Pythonå’ŒYOLOè¿›è¡Œé›¶ä»¶è¡¨é¢ç‘•ç–µæ£€æµ‹çš„å¾®è°ƒæ–¹æ¡ˆã€‚åŸºäºä½ çš„éœ€æ±‚ï¼Œæˆ‘æ¨èä½¿ç”¨YOLOv8ï¼Œå®ƒå¯¹ç›®æ ‡æ£€æµ‹å’Œåˆ†ç±»ä»»åŠ¡éƒ½æœ‰å¾ˆå¥½çš„æ”¯æŒã€‚

## å®Œæ•´å®ç°æ–¹æ¡ˆ

### 1. ç¯å¢ƒå‡†å¤‡å’Œä¾èµ–å®‰è£…

```python
# requirements.txt
ultralytics>=8.0.0
opencv-python>=4.5.0
numpy>=1.21.0
matplotlib>=3.5.0
Pillow>=8.3.0
torch>=1.11.0
torchvision>=0.12.0
```

### 2. æ•°æ®å‡†å¤‡å’Œæ ‡æ³¨æ ¼å¼

```python
import os
import json
import cv2
import numpy as np
from pathlib import Path

class DefectDatasetPreparer:
    def __init__(self, data_root):
        self.data_root = Path(data_root)
        self.classes = {
            0: 'AC_Bright',           # æ­£å¸¸-äº®é¢
            1: 'AC_Half_Bright',      # æ­£å¸¸-åŠäº®é¢
            2: 'NC_Greyish',          # ç¼ºé™·-ç°æš—
            3: 'NC_Rusty',            # ç¼ºé™·-é”ˆèš€
            4: 'NC_Peeled',           # ç¼ºé™·-å‰¥è½
            5: 'NC_Scaled'            # ç¼ºé™·-é³ç‰‡çŠ¶
        }
        
    def create_yolo_structure(self):
        """åˆ›å»ºYOLOè®­ç»ƒæ‰€éœ€çš„ç›®å½•ç»“æ„"""
        dirs = ['images/train', 'images/val', 'images/test',
                'labels/train', 'labels/val', 'labels/test']
        
        for dir_name in dirs:
            (self.data_root / dir_name).mkdir(parents=True, exist_ok=True)
            
    def convert_annotations_to_yolo(self, annotation_file, output_dir):
        """å°†æ ‡æ³¨è½¬æ¢ä¸ºYOLOæ ¼å¼
        å‡è®¾åŸå§‹æ ‡æ³¨æ ¼å¼ä¸ºCOCOæˆ–è‡ªå®šä¹‰æ ¼å¼
        """
        with open(annotation_file, 'r') as f:
            annotations = json.load(f)
            
        for ann in annotations:
            image_path = ann['image_path']
            image = cv2.imread(image_path)
            h, w = image.shape[:2]
            
            # è½¬æ¢è¾¹ç•Œæ¡†ä¸ºYOLOæ ¼å¼ (class_id, x_center, y_center, width, height)
            yolo_labels = []
            for obj in ann['objects']:
                class_id = obj['class_id']
                bbox = obj['bbox']  # [x_min, y_min, x_max, y_max]
                
                # è½¬æ¢ä¸ºYOLOæ ¼å¼
                x_center = (bbox[0] + bbox[2]) / 2 / w
                y_center = (bbox[1] + bbox[3]) / 2 / h
                width = (bbox[2] - bbox[0]) / w
                height = (bbox[3] - bbox[1]) / h
                
                yolo_labels.append(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")
            
            # ä¿å­˜YOLOæ ¼å¼æ ‡æ³¨
            label_file = output_dir / f"{Path(image_path).stem}.txt"
            with open(label_file, 'w') as f:
                f.write('\n'.join(yolo_labels))
```

### 3. æ•°æ®å¢å¼ºç­–ç•¥

```python
import albumentations as A
from albumentations.pytorch import ToTensorV2

class DefectAugmentation:
    def __init__(self):
        self.train_transform = A.Compose([
            # å‡ ä½•å˜æ¢ - å¤„ç†é›¶ä»¶æœå‘å’Œä½ç½®ä¸å›ºå®šçš„é—®é¢˜
            A.RandomRotate90(p=0.5),
            A.Rotate(limit=30, p=0.7),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.3),
            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.7),
            
            # å…‰ç…§å˜æ¢ - å¤„ç†åå°„å’Œå…‰çº¿é—®é¢˜
            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),
            A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),
            A.RandomGamma(gamma_limit=(80, 120), p=0.5),
            
            # é¢œè‰²å˜æ¢ - å¢å¼ºå¯¹ä¸åŒè¡¨é¢çŠ¶æ€çš„è¯†åˆ«
            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=20, p=0.6),
            A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),
            
            # å™ªå£°å’Œæ¨¡ç³Š - æ¨¡æ‹ŸçœŸå®ç¯å¢ƒ
            A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),
            A.MotionBlur(blur_limit=3, p=0.3),
            A.GaussianBlur(blur_limit=3, p=0.2),
            
            # é®æŒ¡æ¨¡æ‹Ÿ - å¤„ç†é›¶ä»¶å †å é®æŒ¡é—®é¢˜
            A.CoarseDropout(max_holes=3, max_height=50, max_width=50, p=0.3),
            
        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))
        
        self.val_transform = A.Compose([
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))
```

### 4. YOLOæ¨¡å‹å¾®è°ƒå®ç°

```python
from ultralytics import YOLO
import torch
import yaml
from pathlib import Path

class DefectYOLOTrainer:
    def __init__(self, data_config_path, model_save_dir):
        self.data_config_path = data_config_path
        self.model_save_dir = Path(model_save_dir)
        self.model_save_dir.mkdir(parents=True, exist_ok=True)
        
    def create_data_config(self, train_path, val_path, test_path, class_names):
        """åˆ›å»ºYOLOæ•°æ®é…ç½®æ–‡ä»¶"""
        config = {
            'path': str(Path(train_path).parent.parent),  # æ•°æ®é›†æ ¹ç›®å½•
            'train': 'images/train',
            'val': 'images/val',
            'test': 'images/test',
            'nc': len(class_names),  # ç±»åˆ«æ•°é‡
            'names': class_names     # ç±»åˆ«åç§°
        }
        
        with open(self.data_config_path, 'w') as f:
            yaml.dump(config, f, default_flow_style=False)
            
    def train_model(self, model_size='n', epochs=100, imgsz=640, batch_size=16):
        """è®­ç»ƒYOLOæ¨¡å‹"""
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        model = YOLO(f'yolov8{model_size}.pt')
        
        # è®­ç»ƒå‚æ•°é…ç½®
        train_args = {
            'data': self.data_config_path,
            'epochs': epochs,
            'imgsz': imgsz,
            'batch': batch_size,
            'device': 'cuda' if torch.cuda.is_available() else 'cpu',
            'workers': 8,
            'project': str(self.model_save_dir),
            'name': 'defect_detection',
            'save': True,
            'save_period': 10,  # æ¯10ä¸ªepochä¿å­˜ä¸€æ¬¡
            
            # ä¼˜åŒ–å™¨è®¾ç½®
            'optimizer': 'AdamW',
            'lr0': 0.001,
            'weight_decay': 0.0005,
            
            # æ•°æ®å¢å¼º
            'hsv_h': 0.015,
            'hsv_s': 0.7,
            'hsv_v': 0.4,
            'degrees': 15.0,
            'translate': 0.1,
            'scale': 0.5,
            'shear': 0.0,
            'perspective': 0.0,
            'flipud': 0.5,
            'fliplr': 0.5,
            'mosaic': 1.0,
            'mixup': 0.1,
            
            # æŸå¤±å‡½æ•°æƒé‡
            'box': 7.5,
            'cls': 0.5,
            'dfl': 1.5,
            
            # æ—©åœå’Œå­¦ä¹ ç‡è°ƒåº¦
            'patience': 50,
            'cos_lr': True,
        }
        
        # å¼€å§‹è®­ç»ƒ
        results = model.train(**train_args)
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        best_model_path = self.model_save_dir / 'defect_detection' / 'weights' / 'best.pt'
        final_model_path = self.model_save_dir / 'defect_yolo_final.pt'
        
        if best_model_path.exists():
            import shutil
            shutil.copy2(best_model_path, final_model_path)
            print(f"æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°: {final_model_path}")
            
        return results, final_model_path
    
    def evaluate_model(self, model_path, test_data_path):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        model = YOLO(model_path)
        
        # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
        results = model.val(
            data=self.data_config_path,
            split='test',
            imgsz=640,
            batch=16,
            save_json=True,
            save_hybrid=True
        )
        
        return results
```

### 5. æ¨¡å‹æ¨ç†å’Œåº”ç”¨

```python
import cv2
import numpy as np
from ultralytics import YOLO

class DefectDetector:
    def __init__(self, model_path, conf_threshold=0.5, iou_threshold=0.45):
        self.model = YOLO(model_path)
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold
        
        # ç±»åˆ«æ˜ å°„
        self.class_names = {
            0: 'AC_Bright',
            1: 'AC_Half_Bright', 
            2: 'NC_Greyish',
            3: 'NC_Rusty',
            4: 'NC_Peeled',
            5: 'NC_Scaled'
        }
        
        # ç¼ºé™·ç±»åˆ«
        self.defect_classes = {2, 3, 4, 5}
        
    def detect_defects(self, image_path, save_result=True):
        """æ£€æµ‹é›¶ä»¶è¡¨é¢ç¼ºé™·"""
        # æ¨ç†
        results = self.model(
            image_path,
            conf=self.conf_threshold,
            iou=self.iou_threshold,
            save=save_result
        )
        
        # è§£æç»“æœ
        detections = []
        has_defects = False
        
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    class_id = int(box.cls[0])
                    confidence = float(box.conf[0])
                    bbox = box.xyxy[0].tolist()  # [x1, y1, x2, y2]
                    
                    detection = {
                        'class_id': class_id,
                        'class_name': self.class_names[class_id],
                        'confidence': confidence,
                        'bbox': bbox,
                        'is_defect': class_id in self.defect_classes
                    }
                    
                    detections.append(detection)
                    
                    if class_id in self.defect_classes:
                        has_defects = True
        
        return {
            'image_path': image_path,
            'has_defects': has_defects,
            'detections': detections,
            'total_parts': len(detections),
            'defective_parts': sum(1 for d in detections if d['is_defect'])
        }
    
    def batch_detect(self, image_folder, output_file=None):
        """æ‰¹é‡æ£€æµ‹"""
        results = []
        image_folder = Path(image_folder)
        
        for image_path in image_folder.glob('*.jpg'):
            result = self.detect_defects(str(image_path))
            results.append(result)
            
        if output_file:
            import json
            with open(output_file, 'w') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
                
        return results
    
    def visualize_results(self, image_path, detections, save_path=None):
        """å¯è§†åŒ–æ£€æµ‹ç»“æœ"""
        image = cv2.imread(image_path)
        
        for detection in detections:
            bbox = detection['bbox']
            class_name = detection['class_name']
            confidence = detection['confidence']
            is_defect = detection['is_defect']
            
            # è®¾ç½®é¢œè‰²ï¼šç¼ºé™·ç”¨çº¢è‰²ï¼Œæ­£å¸¸ç”¨ç»¿è‰²
            color = (0, 0, 255) if is_defect else (0, 255, 0)
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(image, 
                         (int(bbox[0]), int(bbox[1])), 
                         (int(bbox[2]), int(bbox[3])), 
                         color, 2)
            
            # æ·»åŠ æ ‡ç­¾
            label = f"{class_name}: {confidence:.2f}"
            cv2.putText(image, label, 
                       (int(bbox[0]), int(bbox[1]) - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        if save_path:
            cv2.imwrite(save_path, image)
            
        return image
```

### 6. å®Œæ•´è®­ç»ƒæµç¨‹

```python
def main_training_pipeline():
    """å®Œæ•´çš„è®­ç»ƒæµç¨‹"""
    
    # 1. æ•°æ®å‡†å¤‡
    data_root = "path/to/your/dataset"
    preparer = DefectDatasetPreparer(data_root)
    preparer.create_yolo_structure()
    
    # 2. åˆ›å»ºæ•°æ®é…ç½®
    class_names = ['AC_Bright', 'AC_Half_Bright', 'NC_Greyish', 
                   'NC_Rusty', 'NC_Peeled', 'NC_Scaled']
    
    trainer = DefectYOLOTrainer(
        data_config_path="defect_data.yaml",
        model_save_dir="models"
    )
    
    trainer.create_data_config(
        train_path=f"{data_root}/images/train",
        val_path=f"{data_root}/images/val", 
        test_path=f"{data_root}/images/test",
        class_names=class_names
    )
    
    # 3. è®­ç»ƒæ¨¡å‹
    print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
    results, model_path = trainer.train_model(
        model_size='s',  # å¯é€‰: n, s, m, l, x
        epochs=200,
        imgsz=640,
        batch_size=16
    )
    
    # 4. è¯„ä¼°æ¨¡å‹
    print("è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
    eval_results = trainer.evaluate_model(model_path, f"{data_root}/images/test")
    
    # 5. æµ‹è¯•æ¨ç†
    print("æµ‹è¯•æ¨¡å‹æ¨ç†...")
    detector = DefectDetector(model_path)
    
    # å•å¼ å›¾ç‰‡æµ‹è¯•
    test_image = "path/to/test/image.jpg"
    detection_result = detector.detect_defects(test_image)
    
    print(f"æ£€æµ‹ç»“æœ: {detection_result}")
    
    return model_path, detector

if __name__ == "__main__":
    model_path, detector = main_training_pipeline()
    print(f"è®­ç»ƒå®Œæˆï¼æ¨¡å‹ä¿å­˜åœ¨: {model_path}")
```

### 7. æ¨¡å‹ä¿å­˜å’ŒåŠ è½½

```python
class ModelManager:
    @staticmethod
    def save_model_with_metadata(model_path, metadata):
        """ä¿å­˜æ¨¡å‹å’Œå…ƒæ•°æ®"""
        import pickle
        
        model_dir = Path(model_path).parent
        metadata_path = model_dir / "model_metadata.pkl"
        
        with open(metadata_path, 'wb') as f:
            pickle.dump(metadata, f)
            
        print(f"æ¨¡å‹å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {metadata_path}")
    
    @staticmethod
    def load_model_with_metadata(model_path):
        """åŠ è½½æ¨¡å‹å’Œå…ƒæ•°æ®"""
        import pickle
        
        model_dir = Path(model_path).parent
        metadata_path = model_dir / "model_metadata.pkl"
        
        detector = DefectDetector(model_path)
        
        metadata = None
        if metadata_path.exists():
            with open(metadata_path, 'rb') as f:
                metadata = pickle.load(f)
                
        return detector, metadata

# ä½¿ç”¨ç¤ºä¾‹
metadata = {
    'training_date': '2024-01-01',
    'dataset_size': 10000,
    'classes': ['AC_Bright', 'AC_Half_Bright', 'NC_Greyish', 'NC_Rusty', 'NC_Peeled', 'NC_Scaled'],
    'performance_metrics': {
        'mAP50': 0.85,
        'mAP50-95': 0.72
    }
}

ModelManager.save_model_with_metadata("models/defect_yolo_final.pt", metadata)
```

## å…³é”®è¦ç‚¹

1. **æ•°æ®æ ‡æ³¨**: ç¡®ä¿å‡†ç¡®æ ‡æ³¨æ‰€æœ‰ç±»åˆ«ï¼Œç‰¹åˆ«æ³¨æ„ACå’ŒNCçš„åŒºåˆ†
2. **æ•°æ®å¢å¼º**: é‡ç‚¹å¤„ç†å…‰ç…§å˜åŒ–å’Œé›¶ä»¶æœå‘é—®é¢˜
3. **ç±»åˆ«å¹³è¡¡**: ç”±äºACæ ·æœ¬è¾ƒå¤šï¼Œè€ƒè™‘ä½¿ç”¨ç±»åˆ«æƒé‡æˆ–é‡é‡‡æ ·
4. **æ¨¡å‹é€‰æ‹©**: å»ºè®®ä»YOLOv8så¼€å§‹ï¼Œæ ¹æ®ç²¾åº¦è¦æ±‚è°ƒæ•´æ¨¡å‹å¤§å°
5. **è¶…å‚æ•°è°ƒä¼˜**: æ ¹æ®éªŒè¯é›†è¡¨ç°è°ƒæ•´å­¦ä¹ ç‡ã€batch sizeç­‰å‚æ•°

è¿™ä¸ªæ–¹æ¡ˆå¯ä»¥æœ‰æ•ˆå¤„ç†ä½ æè¿°çš„é›¶ä»¶è¡¨é¢ç‘•ç–µæ£€æµ‹ä»»åŠ¡ï¼ŒåŒ…æ‹¬å¤„ç†å †å é®æŒ¡ã€å…‰ç…§å˜åŒ–ç­‰æŒ‘æˆ˜ã€‚


---

## æ¦‚è§ˆ

è¦ä»å¤´å¼€å§‹å®ç°ç¼ºé™·æ£€æµ‹çš„**Fineâ€‘tuning**ï¼Œä¸»è¦æµç¨‹åŒ…æ‹¬ï¼š

1. **é€‰æ‹©é¢„è®­ç»ƒæ¡†æ¶**ï¼ˆå¦‚ Detectron2ã€MMDetectionã€YOLOv5/YOLOv8ï¼‰ï¼Œ
2. **å‡†å¤‡æ•°æ®é›†**ï¼ˆæ ‡æ³¨ã€è½¬ä¸º COCO/YOLO æ ¼å¼ï¼‰ï¼Œ
3. **æ­å»ºç¯å¢ƒ**ï¼ˆå®‰è£…ä¾èµ–ã€å…‹éš†ä»“åº“ï¼‰ï¼Œ
4. **ä¿®æ”¹é…ç½®æ–‡ä»¶**ï¼ˆæŒ‡å®šç±»åˆ«ã€å†»ç»“å±‚æ•°ç­‰ï¼‰ï¼Œ
5. **å¯åŠ¨è®­ç»ƒ**ï¼ˆè®¾ç½®è®­ç»ƒå‚æ•°ï¼‰ï¼Œ
6. **è¶…å‚æ•°è°ƒä¼˜**ï¼ˆå­¦ä¹ ç‡ã€Momentum ç­‰ï¼‰ä¸
7. **æ¨¡å‹è¯„ä¼°å’Œéƒ¨ç½²**ã€‚

ä¸‹é¢å°†é€æ­¥å±•å¼€æ¯ä¸ªç¯èŠ‚çš„å…·ä½“æ“ä½œå’Œæ³¨æ„äº‹é¡¹ã€‚

---

## 1. é€‰æ‹©åˆé€‚çš„é¢„è®­ç»ƒæ¡†æ¶

### Detectron2

* Facebook å‡ºå“ï¼ŒåŸºäº PyTorchï¼Œç®€æ´æ˜“ç”¨ã€‚å¯ç›´æ¥ä» Model Zoo æ‹‰å– Faster Râ€‘CNNã€Mask Râ€‘CNN ç­‰æ£€æµ‹æ¨¡å‹ï¼Œå¹¶å¯¹è‡ªå®šä¹‰æ•°æ®å¾®è°ƒï¼ˆfineâ€‘tuneï¼‰ã€([Medium][1])ã€‘ã€([Roboflow Blog][2])ã€‘ã€‚

### MMDetection

* OpenMMLab ç”Ÿæ€ä¸‹çš„ Detection å·¥å…·ç®±ï¼ŒåŒæ ·æä¾›ä¸°å¯Œçš„é¢„è®­ç»ƒæ¨¡å‹å’Œé…ç½®ç»§æ‰¿æœºåˆ¶ã€‚é€šè¿‡ç»§æ‰¿ `_base_/models/...` å’Œ `_base_/datasets/...` ç­‰é…ç½®ï¼Œå³å¯å¿«é€Ÿé€‚é…æ–°æ•°æ®é›†ã€([MMDetection][3])ã€‘ã€([MMDetection][4])ã€‘ã€‚

### YOLO ç³»åˆ—

* **YOLOv5**ï¼šUltralytics æä¾›è¯¦ç»†æ•™ç¨‹ï¼Œæ•°æ®å‡†å¤‡ã€é…ç½®å’Œè®­ç»ƒåªéœ€æ•°è¡Œä»£ç ï¼Œå¯å¿«é€Ÿä¸Šæ‰‹ã€([Ultralytics Docs][5])ã€‘ã€‚
* **YOLOv8**ï¼šæœ€æ–°ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡åˆ†å±‚è§£å†»ï¼ˆunfreezeï¼‰å¾®è°ƒå¯ä»¥åœ¨æ–°ä»»åŠ¡ä¸Šå¤§å¹…æå‡ mAPï¼ŒåŒæ—¶ä¿æŒ COCO åŸºå‡†æ€§èƒ½ä¸å˜ã€([arXiv][6])ã€‘ã€‚

---

## 2. æ•°æ®é›†å‡†å¤‡

1. **æ”¶é›†ä¸æ ‡æ³¨**ï¼šä½¿ç”¨ LabelMeã€Makesense.ai æˆ– Roboflow è¿›è¡Œç‰©ä½“è¾¹ç•Œæ¡†ï¼ˆbounding boxï¼‰æ ‡æ³¨ã€‚
2. **æ ¼å¼è½¬æ¢**ï¼š

   * COCO æ ¼å¼ï¼šå¸¸è§äº Detectron2/MMDetectionï¼Œéœ€ç”Ÿæˆ `annotations.json`ï¼Œé”®åŒ…æ‹¬ `images`, `annotations`, `categories`ã€([MMDetection][3])ã€‘ã€‚
   * YOLO æ ¼å¼ï¼šæ¯å¼ å›¾ç‰‡å¯¹åº”ä¸€ä¸ª `.txt` æ–‡ä»¶ï¼Œè¡Œæ ¼å¼ `<class_id> <x_center> <y_center> <width> <height>`ï¼ˆå½’ä¸€åŒ–åæ ‡ï¼‰ã€([DigitalOcean][7])ã€‘ã€‚
3. **æ•°æ®åˆ’åˆ†**ï¼šä¸€èˆ¬æŒ‰ 8:1:1 åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ï¼Œç¡®ä¿ç±»åˆ«åˆ†å¸ƒå‡åŒ€ã€‚

---

## 3. ç¯å¢ƒæ­å»ºä¸ä¾èµ–å®‰è£…

ä»¥ Detectron2 ä¸ºä¾‹ï¼š

```bash
# å®‰è£… Detectron2ï¼ˆéœ€åŒ¹é… PyTorch ç‰ˆæœ¬ï¼‰
pip install detectron2 -f \
  https://dl.fbaipublicfiles.com/detectron2/wheels/cu113/torch1.10/index.html
```

ä»¥ MMDetection ä¸ºä¾‹ï¼š

```bash
git clone https://github.com/open-mmlab/mmdetection.git
cd mmdetection
pip install -r requirements/build.txt
pip install -v -e .
```

ä»¥ YOLOv5 ä¸ºä¾‹ï¼š

```bash
git clone https://github.com/ultralytics/yolov5
cd yolov5
pip install -r requirements.txt
```

ä»¥ä¸Šæ­¥éª¤å‡åœ¨ Pythonâ‰¥3.8ã€PyTorchâ‰¥1.8 ç¯å¢ƒä¸‹è¿›è¡Œã€([Ultralytics Docs][5], [GitHub][8])ã€‘ã€‚

---

## 4. ä¿®æ”¹é…ç½®æ–‡ä»¶

### Detectron2

* åœ¨ç¤ºä¾‹é…ç½® `configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml` ä¸Šï¼š

  1. ä¿®æ”¹ `DATASETS.TRAIN`ã€`DATASETS.TEST` æŒ‡å‘è‡ªå®šä¹‰æ•°æ®é›†åç§°ï¼›
  2. è°ƒæ•´ `SOLVER.BASE_LR`, `SOLVER.MAX_ITER` ç­‰ï¼›
  3. å¯é€šè¿‡ `cfg.MODEL.BACKBONE.FREEZE_AT` å†³å®šå†»ç»“å±‚çº§ã€‚

### MMDetection

* ç¼–å†™æ–°é…ç½®ç»§æ‰¿ï¼š

  ```yaml
  _base_ = [
    '../_base_/models/faster_rcnn_r50_fpn.py',
    '../_base_/datasets/coco_detection.py',
    '../_base_/schedules/schedule_1x.py',
    '../_base_/default_runtime.py'
  ]
  model = dict(
    roi_head=dict(
      bbox_head=dict(num_classes=ä½ çš„ç±»åˆ«æ•°)
    )
  )
  data = dict(
    train=dict(ann_file='path/to/train.json', img_prefix='train/'),
    val=dict(ann_file='path/to/val.json', img_prefix='val/')
  )
  ```
* ç»§æ‰¿é¿å…é‡å¤é…ç½®ï¼Œå¹¶ä¿è¯ä¸ Model Zoo å…¼å®¹ã€([MMDetection][3])ã€‘ã€‚

### YOLOv5/YOLOv8

* ç¼–è¾‘ `data.yaml`ï¼š

  ```yaml
  train: path/to/images/train
  val:   path/to/images/val
  nc:    ç±»åˆ«æ•°
  names: ['defect1','defect2',...]
  ```
* é€‰æ‹©é¢„è®­ç»ƒæƒé‡ï¼ˆå¦‚ `yolov5s.pt`ï¼‰ï¼Œå¹¶åœ¨è®­ç»ƒå‘½ä»¤ä¸­æŒ‡å®šå†»ç»“å±‚æ•°ï¼š

  ```bash
  python train.py --img 640 --batch 16 --epochs 50 \
    --data data.yaml --cfg yolov5s.yaml --weights yolov5s.pt \
    --freeze 10
  ```

  å…¶ä¸­ `--freeze` æ§åˆ¶å†»ç»“å‰ N å±‚ï¼Œå‚è€ƒæœ€æ–°ç ”ç©¶å¯æ ¹æ®ä»»åŠ¡éœ€æ±‚è°ƒæ•´æ·±åº¦ã€([arXiv][6])ã€‘ã€‚

---

## 5. å¯åŠ¨è®­ç»ƒ

* **Detectron2**ï¼š

  ```bash
  python tools/train_net.py \
    --config-file configs/YourConfig.yaml \
    --num-gpus 1
  ```
* **MMDetection**ï¼š

  ```bash
  ./tools/dist_train.sh \
    configs/your/finetune_config.py 1
  ```
* **YOLOv5**ï¼š

  ```bash
  python train.py \
    --data data.yaml --weights yolov5s.pt \
    --epochs 50 --batch-size 16
  ```

è®­ç»ƒè¿‡ç¨‹ä¸­å¯å®æ—¶è¾“å‡º mAPã€loss æ›²çº¿ï¼Œå¹¶åœ¨éªŒè¯é›†ä¸Šç›‘æ§æ€§èƒ½ã€‚

---

## 6. è¶…å‚æ•°ä¸è°ƒä¼˜

* **å­¦ä¹ ç‡ (LR)**ï¼šä¸€èˆ¬åˆå§‹è®¾ä¸º `1e-3`\~`1e-4`ï¼Œå¯ä½¿ç”¨ Warmup ä¸ LR Schedulerï¼ˆStepã€Cosineï¼‰è¿›è¡ŒåŠ¨æ€è°ƒæ•´ã€([arXiv][9])ã€‘ã€‚
* **Momentum & Weight Decay**ï¼šMomentum å»ºè®® 0.9 å·¦å³ï¼ŒWeight Decay å¯å°è¯• `1e-4`\~`1e-5`ï¼Œè§†ä»»åŠ¡å’Œæ•°æ®é‡å¾®è°ƒã€([arXiv][9])ã€‘ã€‚
* **å†»ç»“ç­–ç•¥**ï¼šå¦‚ YOLOv8 ç ”ç©¶æ‰€ç¤ºï¼Œé€æ­¥è§£å†»ï¼ˆfreeze pointsï¼‰å¯æå‡ç»†ç²’åº¦æ£€æµ‹æ€§èƒ½ï¼ŒåŒæ—¶é¿å…é—å¿˜åŸæ¨¡å‹èƒ½åŠ›ã€([arXiv][6])ã€‘ã€‚

---

## 7. æ¨¡å‹è¯„ä¼°ä¸éƒ¨ç½²

1. **è¯„ä¼°**ï¼šä½¿ç”¨ COCO API è®¡ç®— APã€mAPã€Recall ç­‰æŒ‡æ ‡ï¼›
2. **å¯¼å‡ºæƒé‡**ï¼šDetectron2 å¯å¯¼å‡º `.pth`ï¼ŒMMDetection åŒç†ï¼›YOLOv5 æ”¯æŒå¯¼å‡º ONNX/ TorchScriptï¼›
3. **éƒ¨ç½²**ï¼š

   * äº‘ç«¯æœåŠ¡ï¼ˆFlask/GPUï¼‰ï¼›
   * è¾¹ç¼˜ç«¯ï¼ˆTensorRTã€OpenVINOï¼‰ï¼›
   * é›†æˆåˆ° ROS/å·¥ä¸šæµæ°´çº¿ã€‚

---

é€šè¿‡ä¸Šè¿°æ­¥éª¤ï¼Œä½ å³å¯ä»é›¶å¼€å§‹å®ŒæˆåŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„ç¼ºé™·æ£€æµ‹ Fineâ€‘tuningã€‚æ ¹æ®é¡¹ç›®éœ€æ±‚ï¼Œçµæ´»é€‰æ‹©æ¡†æ¶å’Œè¶…å‚æ•°ï¼Œå¹¶åœ¨è®­ç»ƒä¸­ä¸æ–­è¿­ä»£ä¼˜åŒ–ã€‚ç¥ä½ æ—©æ—¥å®ç°é«˜ç²¾åº¦ã€å®æ—¶çš„ç¼ºé™·æ£€æµ‹ç³»ç»Ÿï¼

[1]: https://medium.com/the-owl/guide-to-fine-tuning-a-pre-trained-model-for-object-detection-tasks-with-faster-rcnn-using-e2e7e190105b?utm_source=chatgpt.com "Guide to fine-tuning a Pre-trained model for Object Detection tasks ..."
[2]: https://blog.roboflow.com/how-to-train-detectron2/?utm_source=chatgpt.com "How to Train Detectron2 on Custom Object Detection Data"
[3]: https://mmdetection.readthedocs.io/en/v2.9.0/tutorials/finetune.html?utm_source=chatgpt.com "Tutorial 7: Finetuning Models - MMDetection's documentation!"
[4]: https://mmdetection.readthedocs.io/en/latest/user_guides/train.html?utm_source=chatgpt.com "Train predefined models on standard datasets"
[5]: https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/?utm_source=chatgpt.com "Train YOLOv5 on Custom Data - Ultralytics YOLO Docs"
[6]: https://arxiv.org/abs/2505.01016?utm_source=chatgpt.com "Fine-Tuning Without Forgetting: Adaptation of YOLOv8 Preserves COCO Performance"
[7]: https://www.digitalocean.com/community/tutorials/train-yolov5-custom-data?utm_source=chatgpt.com "How to Train YOLO v5 on a Custom Dataset | DigitalOcean"
[8]: https://github.com/open-mmlab/mmdetection?utm_source=chatgpt.com "open-mmlab/mmdetection: OpenMMLab Detection Toolbox ... - GitHub"
[9]: https://arxiv.org/abs/2002.11770?utm_source=chatgpt.com "Rethinking the Hyperparameters for Fine-tuning"


---

ä½¿ç”¨YOLO11ï¼ˆYOLOv11ï¼‰æ˜¯ä¸ªå¾ˆå¥½çš„é€‰æ‹©ï¼YOLO11æ˜¯æœ€æ–°ç‰ˆæœ¬ï¼Œæ€§èƒ½æ›´ä¼˜ç§€ã€‚è®©æˆ‘ä¸ºä½ æä¾›å®Œæ•´çš„ç¯å¢ƒé…ç½®å’Œä»£ç å®ç°ã€‚

## ç¯å¢ƒé…ç½®

### 1. Pythonç‰ˆæœ¬è¦æ±‚
```bash
# æ¨èä½¿ç”¨ Python 3.8-3.11
python --version  # ç¡®ä¿æ˜¯ 3.8+ ç‰ˆæœ¬
```

### 2. å®‰è£…ä¾èµ–
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
conda create -n yolo11_defect python=3.10
conda activate yolo11_defect

# æˆ–ä½¿ç”¨ venv
python -m venv yolo11_env
source yolo11_env/bin/activate  # Linux/Mac
# yolo11_env\Scripts\activate  # Windows

# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install ultralytics>=8.3.0  # YOLO11 éœ€è¦æœ€æ–°ç‰ˆæœ¬
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  # CUDAç‰ˆæœ¬
# å¦‚æœæ²¡æœ‰GPUï¼Œä½¿ç”¨CPUç‰ˆæœ¬ï¼š
# pip install torch torchvision torchaudio

# å…¶ä»–ä¾èµ–
pip install opencv-python>=4.8.0
pip install numpy>=1.24.0
pip install matplotlib>=3.7.0
pip install Pillow>=10.0.0
pip install albumentations>=1.3.0
pip install pandas>=2.0.0
pip install seaborn>=0.12.0
pip install tqdm>=4.65.0
```

### 3. éªŒè¯å®‰è£…
```python
import ultralytics
print(f"Ultralytics version: {ultralytics.__version__}")

from ultralytics import YOLO
# è¿™ä¼šè‡ªåŠ¨ä¸‹è½½YOLO11æ¨¡å‹
model = YOLO('yolo11n.pt')
print("YOLO11 å®‰è£…æˆåŠŸï¼")
```

## YOLO11 ä¸“ç”¨ä»£ç å®ç°

### 1. YOLO11 è®­ç»ƒå™¨ï¼ˆæ›´æ–°ç‰ˆæœ¬ï¼‰

```python
from ultralytics import YOLO
import torch
import yaml
from pathlib import Path
import json

class YOLO11DefectTrainer:
    def __init__(self, data_config_path, model_save_dir):
        self.data_config_path = data_config_path
        self.model_save_dir = Path(model_save_dir)
        self.model_save_dir.mkdir(parents=True, exist_ok=True)
        
        # YOLO11 å¯ç”¨çš„æ¨¡å‹å°ºå¯¸
        self.available_models = {
            'n': 'yolo11n.pt',      # Nano - æœ€å¿«
            's': 'yolo11s.pt',      # Small - å¹³è¡¡
            'm': 'yolo11m.pt',      # Medium - æ›´å¥½ç²¾åº¦
            'l': 'yolo11l.pt',      # Large - é«˜ç²¾åº¦
            'x': 'yolo11x.pt'       # Extra Large - æœ€é«˜ç²¾åº¦
        }
        
    def create_data_config(self, train_path, val_path, test_path, class_names):
        """åˆ›å»ºYOLO11æ•°æ®é…ç½®æ–‡ä»¶"""
        config = {
            'path': str(Path(train_path).parent.parent),
            'train': 'images/train',
            'val': 'images/val', 
            'test': 'images/test',
            'nc': len(class_names),
            'names': class_names
        }
        
        with open(self.data_config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
            
    def train_model(self, model_size='s', epochs=200, imgsz=640, batch_size=16):
        """ä½¿ç”¨YOLO11è®­ç»ƒæ¨¡å‹"""
        
        # åŠ è½½YOLO11é¢„è®­ç»ƒæ¨¡å‹
        model_name = self.available_models.get(model_size, 'yolo11s.pt')
        print(f"åŠ è½½YOLO11æ¨¡å‹: {model_name}")
        model = YOLO(model_name)
        
        # YOLO11 ä¼˜åŒ–çš„è®­ç»ƒå‚æ•°
        train_args = {
            'data': self.data_config_path,
            'epochs': epochs,
            'imgsz': imgsz,
            'batch': batch_size,
            'device': 'cuda' if torch.cuda.is_available() else 'cpu',
            'workers': 8,
            'project': str(self.model_save_dir),
            'name': 'yolo11_defect_detection',
            'save': True,
            'save_period': 10,
            'cache': True,  # ç¼“å­˜æ•°æ®é›†ä»¥åŠ é€Ÿè®­ç»ƒ
            
            # YOLO11 ä¼˜åŒ–å™¨è®¾ç½®
            'optimizer': 'auto',  # YOLO11 è‡ªåŠ¨é€‰æ‹©æœ€ä½³ä¼˜åŒ–å™¨
            'lr0': 0.01,          # åˆå§‹å­¦ä¹ ç‡
            'lrf': 0.01,          # æœ€ç»ˆå­¦ä¹ ç‡ (lr0 * lrf)
            'momentum': 0.937,
            'weight_decay': 0.0005,
            'warmup_epochs': 3.0,
            'warmup_momentum': 0.8,
            'warmup_bias_lr': 0.1,
            
            # YOLO11 æ•°æ®å¢å¼ºï¼ˆæ›´å…ˆè¿›ï¼‰
            'hsv_h': 0.015,
            'hsv_s': 0.7,
            'hsv_v': 0.4,
            'degrees': 0.0,       # æ—‹è½¬è§’åº¦
            'translate': 0.1,     # å¹³ç§»
            'scale': 0.5,         # ç¼©æ”¾
            'shear': 0.0,         # å‰ªåˆ‡
            'perspective': 0.0,   # é€è§†å˜æ¢
            'flipud': 0.0,        # ä¸Šä¸‹ç¿»è½¬
            'fliplr': 0.5,        # å·¦å³ç¿»è½¬
            'bgr': 0.0,           # BGRé€šé“ç¿»è½¬
            'mosaic': 1.0,        # Mosaicå¢å¼º
            'mixup': 0.0,         # Mixupå¢å¼º
            'copy_paste': 0.0,    # Copy-pasteå¢å¼º
            
            # YOLO11 æŸå¤±å‡½æ•°æƒé‡
            'box': 7.5,           # è¾¹ç•Œæ¡†æŸå¤±æƒé‡
            'cls': 0.5,           # åˆ†ç±»æŸå¤±æƒé‡
            'dfl': 1.5,           # DFLæŸå¤±æƒé‡
            
            # è®­ç»ƒç­–ç•¥
            'patience': 100,      # æ—©åœè€å¿ƒå€¼
            'close_mosaic': 10,   # æœ€åNä¸ªepochå…³é—­mosaic
            'amp': True,          # è‡ªåŠ¨æ··åˆç²¾åº¦
            'fraction': 1.0,      # ä½¿ç”¨æ•°æ®é›†çš„æ¯”ä¾‹
            'profile': False,     # æ€§èƒ½åˆ†æ
            'freeze': None,       # å†»ç»“å±‚æ•°
            
            # éªŒè¯è®¾ç½®
            'val': True,
            'split': 'val',
            'save_json': True,
            'save_hybrid': True,
            'conf': 0.001,        # éªŒè¯æ—¶çš„ç½®ä¿¡åº¦é˜ˆå€¼
            'iou': 0.6,           # éªŒè¯æ—¶çš„IoUé˜ˆå€¼
            'max_det': 300,       # æœ€å¤§æ£€æµ‹æ•°é‡
            'half': False,        # åŠç²¾åº¦éªŒè¯
            'dnn': False,         # ä½¿ç”¨OpenCV DNN
            'plots': True,        # ä¿å­˜è®­ç»ƒå›¾è¡¨
        }
        
        print("å¼€å§‹YOLO11è®­ç»ƒ...")
        print(f"ä½¿ç”¨è®¾å¤‡: {train_args['device']}")
        print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"å›¾åƒå°ºå¯¸: {imgsz}")
        
        # å¼€å§‹è®­ç»ƒ
        results = model.train(**train_args)
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        best_model_path = self.model_save_dir / 'yolo11_defect_detection' / 'weights' / 'best.pt'
        final_model_path = self.model_save_dir / 'yolo11_defect_final.pt'
        
        if best_model_path.exists():
            import shutil
            shutil.copy2(best_model_path, final_model_path)
            print(f"âœ… æœ€ä½³YOLO11æ¨¡å‹å·²ä¿å­˜åˆ°: {final_model_path}")
            
        return results, final_model_path
    
    def validate_model(self, model_path):
        """éªŒè¯YOLO11æ¨¡å‹"""
        model = YOLO(model_path)
        
        # YOLO11 éªŒè¯å‚æ•°
        val_results = model.val(
            data=self.data_config_path,
            imgsz=640,
            batch=16,
            conf=0.001,
            iou=0.6,
            max_det=300,
            half=False,
            device='cuda' if torch.cuda.is_available() else 'cpu',
            dnn=False,
            plots=True,
            save_json=True,
            save_hybrid=True,
            verbose=True
        )
        
        return val_results
```

### 2. YOLO11 æ£€æµ‹å™¨

```python
import cv2
import numpy as np
from ultralytics import YOLO
from pathlib import Path
import json

class YOLO11DefectDetector:
    def __init__(self, model_path, conf_threshold=0.5, iou_threshold=0.45):
        self.model = YOLO(model_path)
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold
        
        # ç±»åˆ«æ˜ å°„
        self.class_names = {
            0: 'AC_Bright',
            1: 'AC_Half_Bright', 
            2: 'NC_Greyish',
            3: 'NC_Rusty',
            4: 'NC_Peeled',
            5: 'NC_Scaled'
        }
        
        # ç¼ºé™·ç±»åˆ«
        self.defect_classes = {2, 3, 4, 5}
        
    def detect_defects(self, image_path, save_result=True, save_dir="runs/detect"):
        """ä½¿ç”¨YOLO11æ£€æµ‹é›¶ä»¶è¡¨é¢ç¼ºé™·"""
        
        # YOLO11 æ¨ç†å‚æ•°
        results = self.model(
            image_path,
            conf=self.conf_threshold,
            iou=self.iou_threshold,
            max_det=300,
            device='cuda' if torch.cuda.is_available() else 'cpu',
            half=False,
            augment=False,  # TTA (Test Time Augmentation)
            agnostic_nms=False,
            retina_masks=False,
            save=save_result,
            save_dir=save_dir,
            save_txt=True,
            save_conf=True,
            show_labels=True,
            show_conf=True,
            show_boxes=True,
            line_width=2
        )
        
        # è§£æYOLO11ç»“æœ
        detections = []
        has_defects = False
        
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    class_id = int(box.cls[0])
                    confidence = float(box.conf[0])
                    bbox = box.xyxy[0].tolist()  # [x1, y1, x2, y2]
                    
                    detection = {
                        'class_id': class_id,
                        'class_name': self.class_names.get(class_id, f'Unknown_{class_id}'),
                        'confidence': confidence,
                        'bbox': bbox,
                        'is_defect': class_id in self.defect_classes,
                        'area': (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
                    }
                    
                    detections.append(detection)
                    
                    if class_id in self.defect_classes:
                        has_defects = True
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        defective_parts = [d for d in detections if d['is_defect']]
        normal_parts = [d for d in detections if not d['is_defect']]
        
        return {
            'image_path': image_path,
            'has_defects': has_defects,
            'detections': detections,
            'total_parts': len(detections),
            'defective_parts': len(defective_parts),
            'normal_parts': len(normal_parts),
            'defect_ratio': len(defective_parts) / len(detections) if detections else 0,
            'confidence_stats': {
                'avg_confidence': np.mean([d['confidence'] for d in detections]) if detections else 0,
                'min_confidence': min([d['confidence'] for d in detections]) if detections else 0,
                'max_confidence': max([d['confidence'] for d in detections]) if detections else 0
            }
        }
    
    def batch_detect(self, image_folder, output_file=None, progress_callback=None):
        """æ‰¹é‡æ£€æµ‹"""
        results = []
        image_folder = Path(image_folder)
        
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.webp']
        image_files = []
        for ext in image_extensions:
            image_files.extend(image_folder.glob(ext))
            image_files.extend(image_folder.glob(ext.upper()))
        
        print(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
        
        for i, image_path in enumerate(image_files):
            try:
                result = self.detect_defects(str(image_path), save_result=False)
                results.append(result)
                
                if progress_callback:
                    progress_callback(i + 1, len(image_files))
                else:
                    print(f"å¤„ç†è¿›åº¦: {i+1}/{len(image_files)} - {image_path.name}")
                    
            except Exception as e:
                print(f"å¤„ç†å›¾ç‰‡ {image_path} æ—¶å‡ºé”™: {e}")
                
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
                
        return results
    
    def export_model(self, export_format='onnx', optimize=True):
        """å¯¼å‡ºYOLO11æ¨¡å‹ä¸ºå…¶ä»–æ ¼å¼"""
        export_formats = ['onnx', 'torchscript', 'tensorflow', 'tflite', 'edgetpu', 'coreml']
        
        if export_format not in export_formats:
            raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {export_format}")
            
        print(f"å¯¼å‡ºYOLO11æ¨¡å‹ä¸º {export_format} æ ¼å¼...")
        
        export_path = self.model.export(
            format=export_format,
            imgsz=640,
            keras=False,
            optimize=optimize,
            half=False,
            int8=False,
            dynamic=False,
            simplify=True,
            opset=None,
            workspace=4,
            nms=False
        )
        
        print(f"âœ… æ¨¡å‹å·²å¯¼å‡ºåˆ°: {export_path}")
        return export_path
```

### 3. å®Œæ•´çš„YOLO11è®­ç»ƒæµç¨‹

```python
def main_yolo11_pipeline():
    """å®Œæ•´çš„YOLO11è®­ç»ƒå’Œéƒ¨ç½²æµç¨‹"""
    
    # 1. æ•°æ®å‡†å¤‡
    data_root = "path/to/your/dataset"
    
    # 2. åˆ›å»ºè®­ç»ƒå™¨
    trainer = YOLO11DefectTrainer(
        data_config_path="yolo11_defect_data.yaml",
        model_save_dir="yolo11_models"
    )
    
    # 3. é…ç½®æ•°æ®
    class_names = ['AC_Bright', 'AC_Half_Bright', 'NC_Greyish', 
                   'NC_Rusty', 'NC_Peeled', 'NC_Scaled']
    
    trainer.create_data_config(
        train_path=f"{data_root}/images/train",
        val_path=f"{data_root}/images/val", 
        test_path=f"{data_root}/images/test",
        class_names=class_names
    )
    
    # 4. è®­ç»ƒYOLO11æ¨¡å‹
    print("ğŸš€ å¼€å§‹YOLO11è®­ç»ƒ...")
    results, model_path = trainer.train_model(
        model_size='s',  # æ¨èä»'s'å¼€å§‹
        epochs=200,
        imgsz=640,
        batch_size=16
    )
    
    # 5. éªŒè¯æ¨¡å‹
    print("ğŸ“Š éªŒè¯YOLO11æ¨¡å‹...")
    val_results = trainer.validate_model(model_path)
    
    # 6. åˆ›å»ºæ£€æµ‹å™¨
    print("ğŸ” åˆ›å»ºYOLO11æ£€æµ‹å™¨...")
    detector = YOLO11DefectDetector(model_path)
    
    # 7. æµ‹è¯•æ£€æµ‹
    test_image = "path/to/test/image.jpg"
    if Path(test_image).exists():
        detection_result = detector.detect_defects(test_image)
        print(f"æ£€æµ‹ç»“æœ: {detection_result}")
    
    # 8. å¯¼å‡ºæ¨¡å‹ï¼ˆå¯é€‰ï¼‰
    print("ğŸ“¦ å¯¼å‡ºYOLO11æ¨¡å‹...")
    onnx_path = detector.export_model('onnx')
    
    return model_path, detector

if __name__ == "__main__":
    model_path, detector = main_yolo11_pipeline()
    print(f"âœ… YOLO11è®­ç»ƒå®Œæˆï¼æ¨¡å‹ä¿å­˜åœ¨: {model_path}")
```

### 4. æ€§èƒ½ç›‘æ§å’Œå¯è§†åŒ–

```python
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

class YOLO11Monitor:
    def __init__(self, results_dir):
        self.results_dir = Path(results_dir)
        
    def plot_training_curves(self):
        """ç»˜åˆ¶YOLO11è®­ç»ƒæ›²çº¿"""
        results_csv = self.results_dir / "results.csv"
        
        if not results_csv.exists():
            print("æœªæ‰¾åˆ°è®­ç»ƒç»“æœæ–‡ä»¶")
            return
            
        import pandas as pd
        df = pd.read_csv(results_csv)
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('YOLO11 Training Results', fontsize=16)
        
        # æŸå¤±æ›²çº¿
        axes[0, 0].plot(df['epoch'], df['train/box_loss'], label='Box Loss')
        axes[0, 0].plot(df['epoch'], df['train/cls_loss'], label='Class Loss')
        axes[0, 0].plot(df['epoch'], df['train/dfl_loss'], label='DFL Loss')
        axes[0, 0].set_title('Training Losses')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True)
        
        # mAPæ›²çº¿
        axes[0, 1].plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP@0.5')
        axes[0, 1].plot(df['epoch'], df['metrics/mAP50-95(B)'], label='mAP@0.5:0.95')
        axes[0, 1].set_title('Validation mAP')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('mAP')
        axes[0, 1].legend()
        axes[0, 1].grid(True)
        
        # ç²¾ç¡®ç‡å’Œå¬å›ç‡
        axes[1, 0].plot(df['epoch'], df['metrics/precision(B)'], label='Precision')
        axes[1, 0].plot(df['epoch'], df['metrics/recall(B)'], label='Recall')
        axes[1, 0].set_title('Precision & Recall')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('Score')
        axes[1, 0].legend()
        axes[1, 0].grid(True)
        
        # å­¦ä¹ ç‡
        axes[1, 1].plot(df['epoch'], df['lr/pg0'], label='Learning Rate')
        axes[1, 1].set_title('Learning Rate')
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].set_ylabel('LR')
        axes[1, 1].legend()
        axes[1, 1].grid(True)
        
        plt.tight_layout()
        plt.savefig(self.results_dir / 'training_curves.png', dpi=300, bbox_inches='tight')
        plt.show()
```

## YOLO11 vs YOLO8 ä¸»è¦ä¼˜åŠ¿

1. **æ›´å¥½çš„ç²¾åº¦**: YOLO11åœ¨ç›¸åŒæ¨¡å‹å°ºå¯¸ä¸‹ç²¾åº¦æ›´é«˜
2. **æ›´å¿«çš„æ¨ç†é€Ÿåº¦**: ä¼˜åŒ–çš„ç½‘ç»œç»“æ„
3. **æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›**: æ”¹è¿›çš„è®­ç»ƒç­–ç•¥
4. **æ›´å¥½çš„å°ç›®æ ‡æ£€æµ‹**: å¯¹ä½ çš„é›¶ä»¶å †å åœºæ™¯æ›´æœ‰åˆ©
5. **è‡ªåŠ¨ä¼˜åŒ–å™¨é€‰æ‹©**: è®­ç»ƒæ›´ç¨³å®š

## æ¨èé…ç½®

- **å¼€å‘ç¯å¢ƒ**: Python 3.10 + CUDA 11.8
- **æ¨¡å‹é€‰æ‹©**: ä»YOLO11så¼€å§‹ï¼Œæ ¹æ®ç²¾åº¦è¦æ±‚è°ƒæ•´
- **è®­ç»ƒç­–ç•¥**: ä½¿ç”¨æ›´é•¿çš„è®­ç»ƒå‘¨æœŸï¼ˆ200+ epochsï¼‰
- **æ•°æ®å¢å¼º**: YOLO11å†…ç½®çš„å¢å¼ºç­–ç•¥å·²ç»å¾ˆå¼ºå¤§

è¿™æ ·ä½ å°±å¯ä»¥ä½¿ç”¨æœ€æ–°çš„YOLO11æ¥è®­ç»ƒä½ çš„é›¶ä»¶ç¼ºé™·æ£€æµ‹æ¨¡å‹äº†ï¼
