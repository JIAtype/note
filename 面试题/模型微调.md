# 微调的方法

prompt tuning
p-tuning
lora

前两者的区别是什么
前者固定模型参数，后者引入可训练参数

# LoRA（Low-Rank Adaptation）技术是一种用于深度学习模型，特别是在大规模预训练模型中的参数高效微调的方法。

### 简介
- **全称：** Low-Rank Adaptation
- **领域：** 主要用于自然语言处理（NLP）、计算机视觉等深度学习任务中的模型微调
- **核心思想：** 利用低秩（low-rank）矩阵分解技巧，减少模型在微调时需要更新的参数数量，从而实现高效、低资源的模型适应

### 主要特点
- **参数高效：** 只需微调少量参数，显著减少存储和计算成本
- **保持预训练模型：** 不需要大规模重新训练整个模型，便于迁移和个性化应用
- **适应性强：** 可以在多个任务和场景中使用，效果良好

### 技术细节（简要）
在传统微调中，通常会调整整个模型的参数。而LoRA的做法是在特定层引入低秩补充矩阵（如A和B），只训练这些低秩矩阵，原始模型参数保持不变。例如，如果某一层的权重为W，LoRA会引入两个低秩矩阵A和B，使得：
  
\[ W' = W + \Delta W \]
  
其中：
  
\[ \Delta W = A B \]
  
这里，A和B的秩较低，参数总数大大减少。

### 作用和应用
- **节省存储空间**：尤其适合在资源有限的设备上部署
- **快速适应新任务**：在少量样本或有限时间内快速微调模型
- **适合模型合成和个性化**：如文本生成、图像识别等

### 总结
LoRA是一种用以高效微调大型预训练模型的技术，通过引入低秩矩阵，只调整少部分参数，就能实现模型在新任务上的良好表现，极大地降低了微调成本。

---

选择LoRA（Low-Rank Adaptation）而不是全参数微调，主要有以下几个原因：

1. 显存限制，全量微调存储参数所有参数的梯度，而LoRA只训练低秩矩阵。
2. 避免灾难性遗忘，原始大模型的通用能力得以保留。网格搜索后发现rank（秩）=8时效果最好，但需要反复验证不同rank再验证集上的表现。

1. **参数量更少，节省存储空间**  
   全参数微调需要调整预训练模型的所有参数，通常会带来数亿甚至数十亿的参数更新。而LoRA只需训练和存储少量低秩补充矩阵，大大减少了参数量。这对于存储资源有限的设备（如边缘设备、移动端）尤为重要。

2. **微调速度更快，效率更高**  
   由于只更新少量参数，训练时间明显缩短。可以在更短时间内完成模型适应，节省计算资源。

3. **避免“灾难性遗忘”或过拟合**  
   在用少量参数微调的情况下，模型原有的能力不容易被破坏，更能保持预训练的知识，同时适应新任务。这有助于在多任务或持续学习场景中保持稳定。

4. **便于多任务和多场景切换**  
   使用LoRA可以为不同任务或场景训练不同的低秩补充矩阵，从而实现模型的快速切换和个性化，不需要为每个任务存储完整模型。

5. **降低硬件和存储成本**  
   较少的参数意味着更少的内存和存储需求，更容易在设备端部署。

6. **易于集成和扩展**  
   由于微调的参数较少，可以方便地与现有系统结合，进行快速扩展和部署。

### 总结
**为什么选择LoRA？**  
- 经济高效：参数低、存储少  
- 快速微调：时间短、资源少  
- 模型稳定性强：保持预训练知识  
- 便于多任务管理：个性化与任务切换

相较于全参数微调，LoRA在资源有限、效率优先的场景尤其具有优势。  

---

