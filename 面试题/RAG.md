RAG 检索增强生成（Retrieval Augmented Generation）

[详细讲解](https://zhuanlan.zhihu.com/p/675509396)

RAG（中文为检索增强生成） = 检索技术 + LLM 提示。

通过自有垂域数据库检索相关信息，然后合并成为提示模板，给大模型润色生成回答。

RAG就是通过检索获取相关的知识并将其融入Prompt，让大模型能够参考相应的知识从而给出合理回答。因此，可以将RAG的核心理解为“检索+生成”，前者主要是利用向量数据库的高效存储和检索能力，召回目标知识；后者则是利用大模型和Prompt工程，将召回的知识合理利用，生成目标答案。

解决大模型问题：
- 知识的局限性：模型自身的知识完全源于它的训练数据，而现有的主流大模型（deepseek、文心一言、通义千问…）的训练集基本都是构建于网络公开的数据，对于一些实时性的、非公开的或离线的数据是无法获取到的。
- 幻觉问题：所有的AI模型的底层原理都是基于数学概率，其模型输出实质上是一系列数值运算，大模型也不例外，所以它经常会一本正经地胡说八道，尤其是在大模型自身不具备某一方面的知识或不擅长的场景。
- 数据安全性：对于企业来说，数据安全至关重要，没有企业愿意承担数据泄露的风险，将自身的私域数据上传第三方平台进行训练。这也导致完全依赖通用大模型自身能力的应用方案不得不在数据安全和效果方面进行取舍。

使用例子：
向 LLM 提问一个问题（qustion），RAG 从各种数据源检索相关的信息，并将检索到的信息和问题（answer）注入到 LLM 提示中，LLM 最后给出答案。

有两个主要步骤：语义搜索和生成输出。
在语义搜索步骤中，从知识库中找到与要回答的查询最相关的部分内容。然后，在生成步骤中，将使用这些内容来生成响应。

平台：
基于 LLM 的管道和应用程序的开源库——LangChain 和 LlamaIndex。

---

# RAG流程有哪些？流程中有哪些优化手段？

---

# 如何评价RAG项目的好坏

---

# ragflow和llamaindex区别？

RAGflow和LlamaIndex（之前叫GPT Index）都是用于构建基于大模型的“检索增强”系统的框架或工具，但它们在设计目标、功能和实现方式上存在一些区别。以下是它们的主要区别介绍：

---

## 1. **目标和定位**

### RAGflow
- **主要目标**：提供一个端到端的、基于流水线的检索-生成（Retrieval-Augmented Generation, RAG）流程框架，强调**工作流程的可扩展性、灵活性和自定义能力**。
- **定位**：更偏向于工程化、管道化的实现，适合需要复杂数据流控制、多个检索和生成步骤的应用场景。

### LlamaIndex
- **主要目标**：帮助用户**快速构建基于知识库的问答系统**，简化数据索引、管理和查询工作，强调**易用性、灵活性和数据整合**。
- **定位**：面向开发者及数据科学家，提供便捷的接口快速从原始数据（文档、数据库等）创建索引，集成大模型进行问答。

---

## 2. **设计理念和架构**

### RAGflow
- **架构**：采用类似“管道”或“工作流”的设计，用户可以**自定义检索、处理、生成的多个步骤**，支持复杂的流程编排。
- **特点**：
  - 高度可配置：支持各种检索策略、预处理步骤。
  - 组件化：每个环节可以替换和调整。
  - 适合大规模、多步骤的应用场景。

### LlamaIndex
- **架构**：提供**抽象层级的索引结构**，如树状索引、向量索引、字典索引等，方便存储和检索。
- **特点**：
  - 易用性：一键索引与查询，简化操作。
  - 支持多种数据源：文本、PDF、数据库等。
  - 内置多种索引方式，便于快速搭建问答系统。

---

## 3. **功能模块**

| 特性 / 框架        | RAGflow                                               | LlamaIndex                                      |
|---------------------|--------------------------------------------------------|-------------------------------------------------|
| 核心功能           | 管道式流程设计、复杂检索与生成集成                     | 索引管理、数据整合、问答系统、简易管道          |
| 灵活性             | 高：用户可以自定义每个环节                             | 中：主要支持索引和简单的问答流程              |
| 支持的任务         | 复杂的多步骤检索与文本生成流程                         | 快速搭建知识问答、数据索引、检索增强问答          |
| 扩展能力           | 支持多种检索器、模型和处理方法                         | 支持多种索引类型、数据源快速集成                |

---

## 4. **使用场景举例**

| 场景                  | RAGflow                                              | LlamaIndex                                       |
|-----------------------|------------------------------------------------------|--------------------------------------------------|
| 复杂流水线任务        | 设计复杂多环节的检索和生成流程                      | 更适合快速搭建和调试问答系统                    |
| 定制化流程开发        | 需要详细控制每步流程和处理逻辑                        | 更偏向“开箱即用”模式，极速构建基础应用          |
| 大规模、多源数据管理  | 适合处理复杂的多步、多源数据流                        | 支持多数据源索引，简易管理场景优先                |

---

## 5. **总结**

- **RAGflow**：更偏向于**流程管道设计、企业级应用和大规模定制**，适合需要复杂操作逻辑和高度可扩展性的场景。
- **LlamaIndex**：更偏向于**快速搭建、简便操作和数据整合**，适合快速実践和小到中规模问答应用。

---

# 常用的embedding模型结构是什么？输出向量维度是多少？
以下是常见的 **Embedding 模型结构及其输出向量维度** 的总结，涵盖词向量（Word Embedding）、句子向量（Sentence Embedding）和预训练模型等：

---

### **1. 传统词向量模型**
#### **(1) Word2Vec**
- **结构**：  
  - 采用浅层神经网络，包含输入层、隐藏层（Embedding Layer）和输出层。  
  - 有两种训练模式：  
    - **CBOW（Continuous Bag of Words）**：通过上下文预测目标词。  
    - **Skip-gram**：通过目标词预测上下文。  
- **输出维度**：  
  - 通常为 **100 到 300 维**（例如默认设置为 300 维）。  
- **特点**：  
  - 捕捉词的线性语义关系（如“国王-男人+女人=女王”）。

#### **(2) GloVe（Global Vectors for Word Representation）**
- **结构**：  
  - 结合全局词频统计与局部上下文信息，使用矩阵分解方法生成词向量。  
- **输出维度**：  
  - 常用维度为 **50、100、200、300**（如 GloVe 提供的预训练模型常见 50-300 维）。  
- **特点**：  
  - 平衡全局统计信息与局部上下文，适合捕捉词的全局分布特征。

---

### **2. 神经网络预训练模型**
#### **(1) BERT（Bidirectional Encoder Representations from Transformers）**
- **结构**：  
  - 基于 **Transformer 编码器**，包含多层双向自注意力机制。  
  - 输出每个 token 的上下文感知向量。  
- **输出维度**：  
  - **768 维（Base 版本）** 或 **1024 维（Large 版本）**。  
- **特点**：  
  - 捕捉上下文依赖关系，适用于 NLP 任务（如文本分类、命名实体识别）。  
  - 可通过最后一层的隐藏层输出获取词向量或句子向量。

#### **(2) RoBERTa、DistilBERT、ALBERT**
- **结构**：  
  - BERT 的改进或精简版本（如 RoBERTa 增加训练数据，DistilBERT 压缩模型）。  
- **输出维度**：  
  - 与 BERT 基础版本一致（如 DistilBERT 为 **768 维**）。  

#### **(3) Sentence-BERT（SBERT）**
- **结构**：  
  - 基于 BERT 的扩展，通过对比学习（如 Siamese、Triplet 网络）优化句子向量。  
- **输出维度**：  
  - 继承自 BERT，通常为 **768 或 1024 维**。  
- **特点**：  
  - 直接生成句子级别的向量，适合语义相似度计算。

#### **(4) Word Embedding 层（如在深度学习模型中）**
- **结构**：  
  - 神经网络中的嵌入层（Embedding Layer），将离散词 ID 映射为稠密向量。  
- **输出维度**：  
  - 可自定义，通常为 **100 到 512 维**（如 LSTM/CNN 中常用 256 或 300 维）。  

---

### **3. 其他模型**
#### **(1) ELMO（Embeddings from Language Models）**
- **结构**：  
  - 基于双向 LSTM 的上下文感知模型，输出词的动态向量。  
- **输出维度**：  
  - 默认 **1024 维**（组合前向和后向 LSTM 的输出）。  

#### **(2) Flair**
- **结构**：  
  - 基于字符级 LSTM 的上下文词向量模型。  
- **输出维度**：  
  - 默认 **2048 维**（可调整）。  

#### **(3) GPT（Generative Pre-trained Transformer）**
- **结构**：  
  - 基于 Transformer 解码器的生成模型。  
- **输出维度**：  
  - **768 维（GPT-2）** 或更高（如 GPT-3 的维度更高但通常不直接公开）。  

---

### **4. 输出维度的选择依据**
- **任务需求**：  
  - 简单任务（如文本分类）可选较低维度（如 100-256 维）。  
  - 复杂任务（如语义理解）需更高维度（如 768-1024 维）。  
- **数据量**：  
  - 高维度需要更多训练数据，否则易过拟合。  
- **模型类型**：  
  - 预训练模型（如 BERT）的维度通常固定，用户无法直接修改。  

---

### **5. 示例总结表**
| **模型名称**       | **结构类型**         | **输出维度**       | **典型用途**               |  
|---------------------|----------------------|--------------------|---------------------------|  
| Word2Vec            | 浅层神经网络         | 100-300 维         | 词向量、文本相似度        |  
| GloVe               | 矩阵分解             | 50-300 维          | 词向量、词汇关系分析      |  
| BERT                | Transformer 编码器   | 768/1024 维        | 上下文感知的词/句向量     |  
| Sentence-BERT       | BERT + 对比学习      | 768/1024 维        | 句子相似度、语义检索      |  
| ELMO                | 双向 LSTM            | 1024 维            | 上下文词向量              |  
| GPT-2               | Transformer 解码器   | 768 维             | 文本生成、序列预测        |  

---

### **注意事项**
- **预训练模型**的维度通常不可更改（如 BERT 固定为 768 维），但可以通过后续全连接层调整。  
- **自定义模型**的嵌入层维度需根据任务和数据量实验确定。  
- **句子向量**的维度一般继承自模型（如 BERT 的 768 维），可通过池化操作（如平均、最大池化）生成。

如果需要进一步了解某个模型的具体实现或调参建议，请告诉我！ 😊
---

# 如何切分段落？使用的模型结构是什么？

---

# 
