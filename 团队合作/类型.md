基础模型团队:设计Transformer结构、LLM scaling, multi-modal alignment,这些都是大厂核心组在做,而且后面还会持续做

Infra团队:负责算力调度、并行训练框架、multi-GPU memory优化,面试可能一问就是你有没有写cuda,以及[千卡调度的经验](https://www.53ai.com/news/finetuning/2024091592376.html)

Al product团队:基于大模型构建RAG系统、agent平台、对话插件系统等,拿着公司的私有数据finetune model去解决具体落地问题(applied scientists)

这些岗位共同特征是:不仅要会写代码,更要能理解系统结构、知道怎么落地、怎么调研设计、怎么平衡latency和效果、怎么scale到上线。
它需要的不是“编程技能”,而是“抽象+架构+调度+决策”能力。

LLM岗位的要求：
自学并实现SOTA模型(很多岗位直接要求你复现LLaMA3级别的paper,对模型架构对于面试者要求很高)
能手搓GRPO,DPO,PPO那些,并且还让你说出很多非常细节的东西,xAl,Meta的GenAl组也会要求手推diffusion的

做tokenizer、optimizer、alignment工程,研究前沿试错,做10种MoE结构、100组超参组合、跑上万小时试出来的最优策略。


成本：
GPU采购（A100/H100/GB200）
数据标注、过滤、对齐
训练框架、分布式优化器的搭建

“技术寡头崛起”
模型能力集中在少数几家(OpenAl、Google、Meta、Anthropic)Infra平台集中(NVIDIA、Azure+、AWS+)
应用生态被少数大公司定义(Copilot, Gemini, Claude)
“岗位更集中、更高门槛、更加封闭”基础研究岗位的确在爆发,但要求高到离谱;中低端岗位在萎缩,因为AI反而在自动化掉原本需要人力的部分。
技术发展实在太快了,他们找的人才刚学会GAN,就出现的image diffusion*,然后是video diffusion,公司里那些卡可能连inference都养不起,拿上被新的公司拿着新的技术超越

大模型让上层变得更强，下层变得更自动化
能用LLM做系统整合的》完成整个pipeline》只懂调包用模型

